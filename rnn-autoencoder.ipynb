{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn-autoencoder.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ox7QWf8aMonH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4222df15-ea47-4a0b-f3ae-ddbc219d9a60"
      },
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import reuters\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import get_file\n",
        "from keras.initializers import Constant\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "MAX_NUM_WORDS = 10000\n",
        "MAX_SEQUENCE_LEN = 500"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "bNRgjQjeMonS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7cd7083-19cd-4d14-d320-c3af20683bdc"
      },
      "cell_type": "code",
      "source": [
        "nltk.download('reuters')\n",
        "fileids = reuters.fileids()\n",
        "fileids_test = np.array([fid for fid in fileids if fid.startswith(\"test\")])\n",
        "fileids_train = np.array([fid for fid in fileids if fid.startswith(\"train\")])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_cCRdHLHMonW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer.fit_on_texts(reuters.raw(fid) for fid in fileids)\n",
        "X_train = tokenizer.texts_to_sequences(reuters.raw(fid) for fid in fileids_train)\n",
        "X_test = tokenizer.texts_to_sequences(reuters.raw(fid) for fid in fileids_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_YydNDj8Monb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = sequence.pad_sequences(X_train, maxlen=MAX_SEQUENCE_LEN)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=MAX_SEQUENCE_LEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lajEl4OtMone",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# get glove coeff matrix\n",
        "embeddings_index = {}\n",
        "fname = get_file(\"glove.6B.100d.txt\", \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "                 , extract=True)\n",
        "with open(fname, encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "print('Found %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "# prepare pre-learned embedding matrix\n",
        "embdedding_dim = 100\n",
        "word_index = tokenizer.word_index\n",
        "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
        "embedding_matrix = np.zeros((num_words, embdedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i > MAX_NUM_WORDS:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ovl81uYsMonj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_model(encoder_units=256, decoder_units=256, rnn_layer=layers.GRU):\n",
        "    #embedding = layers.Embedding(num_words, embdedding_dim\n",
        "    #                      , input_length=MAX_SEQUENCE_LEN\n",
        "    #                      , embeddings_initializer=Constant(embedding_matrix), trainable=True)\n",
        "    embedding = layers.Embedding(MAX_NUM_WORDS, 100)\n",
        "    model = Sequential()\n",
        "    model.add(embedding)\n",
        "    model.add(layers.Bidirectional(rnn_layer(encoder_units, return_sequences=False)))\n",
        "    model.add(layers.RepeatVector(MAX_SEQUENCE_LEN))\n",
        "    model.add(layers.Bidirectional(rnn_layer(decoder_units, return_sequences=True)))\n",
        "    model.add(layers.TimeDistributed(layers.Dense(MAX_NUM_WORDS, activation='softmax')))\n",
        "    model.compile(optimizer='adam'\n",
        "                  , loss='categorical_crossentropy'\n",
        "                  , metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hg_MS4xZMonp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "b2784553-d87a-4d87-cfac-b9488f2c8a78"
      },
      "cell_type": "code",
      "source": [
        "model = create_model(rnn_layer=layers.CuDNNGRU)\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 100)         1000000   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 512)               549888    \n",
            "_________________________________________________________________\n",
            "repeat_vector_1 (RepeatVecto (None, 500, 512)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 500, 512)          1182720   \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 500, 10000)        5130000   \n",
            "=================================================================\n",
            "Total params: 7,862,608\n",
            "Trainable params: 7,862,608\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vx0A5YHVMonu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data_generator(X_in, batch_size=32, shuffle=True, repeat=True):\n",
        "    index = np.arange(X_in.shape[0])\n",
        "    while True:\n",
        "        np.random.shuffle(index)\n",
        "        X = X_in[index]\n",
        "        n = X.shape[0]//batch_size\n",
        "        for chunk in np.split(X[:n*batch_size], n):\n",
        "            yield chunk, to_categorical(chunk, MAX_NUM_WORDS)\n",
        "        rest = X[n*batch_size:]\n",
        "        if rest.shape[0]:\n",
        "            yield rest, to_categorical(rest, MAX_NUM_WORDS)\n",
        "        if not repeat:\n",
        "            break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W2rkYzKEMon0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "9aaece2e-ab47-46eb-9c0e-e411dcd8ea2a"
      },
      "cell_type": "code",
      "source": [
        "bs = 32\n",
        "model.fit_generator(data_generator(X_train, batch_size=bs)\n",
        "                    , steps_per_epoch=X_train.shape[0]//bs\n",
        "                    , epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "242/242 [==============================] - 302s 1s/step - loss: 2.4272 - acc: 0.7393\n",
            "Epoch 2/10\n",
            "242/242 [==============================] - 296s 1s/step - loss: 2.0578 - acc: 0.7444\n",
            "Epoch 3/10\n",
            " 75/242 [========>.....................] - ETA: 3:24 - loss: 1.8700 - acc: 0.7444"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BBfKfZzdMon4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_pred = np.argmax(model.predict(X_train[:100], verbose=1), axis=2)\n",
        "X_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Oa3SNWrnMon9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train[:100]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nEKPI4-oMooB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}