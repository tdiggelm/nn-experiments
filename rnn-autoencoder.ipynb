{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn-autoencoder.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ox7QWf8aMonH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4222df15-ea47-4a0b-f3ae-ddbc219d9a60"
      },
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import reuters\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import get_file\n",
        "from keras.initializers import Constant\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "MAX_NUM_WORDS = 10000\n",
        "MAX_SEQUENCE_LEN = 500"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "bNRgjQjeMonS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "187d582e-05ce-4ce7-9418-0a0fb5a80836"
      },
      "cell_type": "code",
      "source": [
        "nltk.download('reuters')\n",
        "nltk.download('punkt')\n",
        "fileids = reuters.fileids()\n",
        "fileids_test = np.array([fid for fid in fileids if fid.startswith(\"test\")])\n",
        "fileids_train = np.array([fid for fid in fileids if fid.startswith(\"train\")])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_cCRdHLHMonW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer.fit_on_texts(reuters.raw(fid) for fid in fileids)\n",
        "X_train = tokenizer.texts_to_sequences(\" \".join(sent) for fid in fileids_train for sent in reuters.sents(fid))\n",
        "X_test = tokenizer.texts_to_sequences(\" \".join(sent) for fid in fileids_test for sent in reuters.sents(fid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_YydNDj8Monb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = sequence.pad_sequences(X_train, maxlen=MAX_SEQUENCE_LEN)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=MAX_SEQUENCE_LEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uOfbjecfafqr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "833ee862-c9ea-44e3-86ef-a0e06b2e4ba5"
      },
      "cell_type": "code",
      "source": [
        "!wget \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "!unzip \"glove.6B.zip\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-13 13:33:04--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-01-13 13:33:04--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip         75%[==============>     ] 623.82M  11.4MB/s    eta 20s    "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lajEl4OtMone",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# get glove coeff matrix\n",
        "embeddings_index = {}\n",
        "with open(\"glove.6B.100d.txt\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "print('Found %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "# prepare pre-learned embedding matrix\n",
        "embdedding_dim = 100\n",
        "word_index = tokenizer.word_index\n",
        "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
        "embedding_matrix = np.zeros((num_words, embdedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i > MAX_NUM_WORDS:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ovl81uYsMonj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_model(encoder_units=256, decoder_units=256, rnn_layer=layers.GRU):\n",
        "    #embedding = layers.Embedding(num_words, embdedding_dim\n",
        "    #                      , input_length=MAX_SEQUENCE_LEN\n",
        "    #                      , embeddings_initializer=Constant(embedding_matrix), trainable=True)\n",
        "    embedding = layers.Embedding(MAX_NUM_WORDS, 100)\n",
        "    model = Sequential()\n",
        "    model.add(embedding)\n",
        "    model.add(layers.Bidirectional(rnn_layer(encoder_units, return_sequences=False)))\n",
        "    model.add(layers.RepeatVector(MAX_SEQUENCE_LEN))\n",
        "    model.add(layers.Bidirectional(rnn_layer(decoder_units, return_sequences=True)))\n",
        "    model.add(layers.TimeDistributed(layers.Dense(MAX_NUM_WORDS, activation='softmax')))\n",
        "    model.compile(optimizer='adam'\n",
        "                  , loss='categorical_crossentropy'\n",
        "                  , metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hg_MS4xZMonp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "b2784553-d87a-4d87-cfac-b9488f2c8a78"
      },
      "cell_type": "code",
      "source": [
        "model = create_model(rnn_layer=layers.CuDNNGRU)\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 100)         1000000   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 512)               549888    \n",
            "_________________________________________________________________\n",
            "repeat_vector_1 (RepeatVecto (None, 500, 512)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 500, 512)          1182720   \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 500, 10000)        5130000   \n",
            "=================================================================\n",
            "Total params: 7,862,608\n",
            "Trainable params: 7,862,608\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vx0A5YHVMonu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data_generator(X_in, batch_size=32, shuffle=True, repeat=True):\n",
        "    index = np.arange(X_in.shape[0])\n",
        "    while True:\n",
        "        np.random.shuffle(index)\n",
        "        X = X_in[index]\n",
        "        n = X.shape[0]//batch_size\n",
        "        for chunk in np.split(X[:n*batch_size], n):\n",
        "            yield chunk, to_categorical(chunk, MAX_NUM_WORDS)\n",
        "        rest = X[n*batch_size:]\n",
        "        if rest.shape[0]:\n",
        "            yield rest, to_categorical(rest, MAX_NUM_WORDS)\n",
        "        if not repeat:\n",
        "            break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W2rkYzKEMon0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "40043e9f-9a7f-45fb-9e1a-d0d0c857b6b3"
      },
      "cell_type": "code",
      "source": [
        "bs = 32\n",
        "model.fit_generator(data_generator(X_train, batch_size=bs)\n",
        "                    , steps_per_epoch=X_train.shape[0]//bs\n",
        "                    , epochs=10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "242/242 [==============================] - 302s 1s/step - loss: 2.4272 - acc: 0.7393\n",
            "Epoch 2/10\n",
            "242/242 [==============================] - 296s 1s/step - loss: 2.0578 - acc: 0.7444\n",
            "Epoch 3/10\n",
            "242/242 [==============================] - 297s 1s/step - loss: 1.7929 - acc: 0.7539\n",
            "Epoch 4/10\n",
            "242/242 [==============================] - 297s 1s/step - loss: 1.7650 - acc: 0.7552\n",
            "Epoch 5/10\n",
            "242/242 [==============================] - 296s 1s/step - loss: 1.7343 - acc: 0.7570\n",
            "Epoch 6/10\n",
            "242/242 [==============================] - 298s 1s/step - loss: 1.7195 - acc: 0.7565\n",
            "Epoch 7/10\n",
            "242/242 [==============================] - 297s 1s/step - loss: 1.7018 - acc: 0.7577\n",
            "Epoch 8/10\n",
            "242/242 [==============================] - 297s 1s/step - loss: 1.7029 - acc: 0.7568\n",
            "Epoch 9/10\n",
            "242/242 [==============================] - 297s 1s/step - loss: 1.6858 - acc: 0.7582\n",
            "Epoch 10/10\n",
            "242/242 [==============================] - 297s 1s/step - loss: 1.6819 - acc: 0.7582\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f75a90d3160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "BBfKfZzdMon4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "3cafddf0-a3f7-4b4b-f246-3da5365a7154"
      },
      "cell_type": "code",
      "source": [
        "tokenizer.sequences_to_texts(np.argmax(model.predict(X_train[:10], verbose=1), axis=2))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r10/10 [==============================] - 0s 45ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the said',\n",
              " 'the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the said',\n",
              " 'lt lt cts cts cts mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln the the the the the the the the the the the the the the the the the of of of of of of of of of of of of of of of of of of of of of of of in dlrs dlrs',\n",
              " 'lt lt lt the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the said',\n",
              " 'lt lt lt lt said the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the said',\n",
              " 'lt lt to to to to to to to to to to to to to to to to to to to to of said said',\n",
              " 'the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the said',\n",
              " 'lt lt shr shr shr net net cts cts cts cts vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs mln mln mln mln mln mln mln mln mln mln mln',\n",
              " 'in in in in in in in in in in in in in in in the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the in in said',\n",
              " 'to to the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the said']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "Oa3SNWrnMon9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "08729599-5f28-4b4f-e148-3d8307255254"
      },
      "cell_type": "code",
      "source": [
        "tokenizer.sequences_to_texts(X_train[:10])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['temporao although normal levels have not been restored smith said in its weekly review the dry period means the temporao will be late this year arrivals for the week ended february 22 were 155 221 bags of 60 kilos making a cumulative total for the season of 5 93 mln against 5 81 at the same stage last year again it seems that cocoa delivered earlier on was included in the arrivals figures smith said there is still some doubt as to how much old crop cocoa is still available as harvesting has come to an end with total bahia crop estimates around 6 4 mln bags and sales standing at almost 6 2 mln there are a few hundred thousand bags still in the hands of farmers exporters and processors there are doubts as to how much of this cocoa would be fit for export as shippers are now in obtaining bahia superior certificates in view of the lower quality over recent weeks farmers have sold a good part of their cocoa held on smith said spot bean prices rose to 340 to 350 cruzados per of 15 kilos bean shippers were reluctant to offer nearby shipment and only limited sales were booked for march shipment at 1 750 to 1 780 dlrs per tonne to ports to be named new crop sales were also light and all to open ports with june july going at 1 850 and 1 880 dlrs and at 35 and 45 dlrs under new york july aug sept at 1 870 1 875 and 1 880 dlrs per tonne fob routine sales of butter were made march april sold at 4 340 4 345 and 4 350 dlrs april may butter went at 2 27 times new york may june july at 4 400 and 4 415 dlrs aug sept at 4 351 to 4 450 dlrs and at 2 27 and 2 28 times new york sept and oct dec at 4 480 dlrs and 2 27 times new york dec smith said destinations were the u s currency areas uruguay and open ports cake sales were registered at 785 to 995 dlrs for march april 785 dlrs for may 753 dlrs for aug and 0 39 times new york dec for oct dec buyers were the u s argentina uruguay and convertible currency areas liquor sales were limited with march april selling at 2 325 and 2 380 dlrs june july at 2 375 dlrs and at 1 25 times new york july aug sept at 2 400 dlrs and at 1 25 times new york sept and oct dec at 1 25 times new york dec smith said total bahia sales are currently estimated at 6 13 mln bags against the 1986 87 crop and 1 06 mln bags against the 1987 88 crop final figures for the period to february 28 are expected to be published by the brazilian cocoa trade commission after which ends midday on february 27',\n",
              " 'computer terminal systems lt completes sale computer terminal systems inc said it has completed the sale of 200 000 shares of its common stock and warrants to acquire an additional one mln shares to lt n v of switzerland for 50 000 dlrs the company said the warrants are exercisable for five years at a purchase price of 125 dlrs per share computer terminal said also has the right to buy additional shares and increase its total holdings up to 40 pct of the computer outstanding common stock under certain circumstances involving change of control at the company the company said if the conditions occur the warrants would be exercisable at a price equal to 75 pct of its common market price at the time not to exceed 1 50 dlrs per share computer terminal also said it sold the rights to its dot impact technology including any future improvements to lt inc of houston tex for 200 000 dlrs but it said it would continue to be the exclusive worldwide licensee of the technology for the company said the moves were part of its reorganization plan and would help pay current operation costs and ensure product delivery computer terminal makes computer generated labels forms and ticket printers and terminals',\n",
              " \"n z trading bank deposit growth rises slightly new zealand's trading bank seasonally adjusted deposit growth rose 2 6 pct in january compared with a rise of 9 4 pct in december the reserve bank said year on year total deposits rose 30 6 pct compared with a 26 3 pct increase in the december year and 34 5 pct rise a year ago period it said in its weekly statistical release total deposits rose to 17 18 billion n z dlrs in january compared with 16 74 billion in december and 13 16 billion in january 1986\",\n",
              " \"national amusements again ups viacom lt via bid viacom international inc said lt national amusements inc has again raised the value of its offer for viacom's publicly held stock the company said the special committee of its board plans to meet later today to consider this offer and the one submitted march one by lt mcv holdings inc a spokeswoman was unable to say if the committee met as planned yesterday viacom said national arsenal holdings inc subsidiary has raised the amount of cash it is offering for each viacom share by 75 cts to 42 75 dlrs while the value of the fraction of a share of exchangeable arsenal holdings preferred to be included was raised 25 cts to 7 75 dlrs national amusements already owns 19 6 pct of viacom's stock\",\n",
              " 'rogers lt sees 1st qtr net up significantly rogers corp said first quarter earnings will be up significantly from earnings of 114 000 dlrs or four cts share for the same quarter last year the company said it expects revenues for the first quarter to be somewhat higher than revenues of 32 9 mln dlrs posted for the year ago quarter rogers said it reached an agreement for the sale of its switch circuit product line to a major supplier the sale terms of which were not disclosed will be completed early in the second quarter rogers said',\n",
              " 'island telephone share split approved lt island telephone co ltd said the previously announced two for one common share split was approved by shareholders at the annual meeting',\n",
              " \"u k growing with japan thatcher prime minister margaret thatcher said the u k was growing more with japanese trade barriers and warned that it would soon have new powers against countries not offering access to their markets she told parliament that the bid by the u k 's cable and wireless plc lt cawl l to enter the japanese telecommunications market was being regarded by her government as a test case i wrote to the prime minister of japan mr nakasone on the fourth of march to express our interest on the cable and wireless bid i have not yet had a reply we see this as a test on how open the japanese market really is thatcher said thatcher told parliament that shortly we shall have more powers than we have now when for example the powers under the financial services act and the banking act become available then we shall be able to take action in cases where other countries do not offer the same full access to financial services as we do cable and wireless is seeking a stake in the proposed japanese telecommunications rival to kokusai denshin denwa but the japanese minister for post and telecommunications was reported as saying that he opposed cable and wireless having a role in the new company\",\n",
              " 'inc lt year net shr loss nil vs profit 19 cts net loss 3 175 vs profit 284 945 revs 13 6 mln vs 10 6 mln year shr profit 13 cts vs profit 56 cts net profit 195 202 vs profit 857 006 revs 47 5 mln vs 42 9 mln note current year net includes charge against discontinued operations of 1 060 848 dlrs',\n",
              " 'canada oil exports rise 20 pct in 1986 canadian oil exports rose 20 pct in 1986 over the previous year to 33 96 mln cubic meters while oil imports soared 25 2 pct to 20 58 mln cubic meters statistics canada said production meanwhile was unchanged from the previous year at 91 09 mln cubic feet natural gas exports plunged 19 4 pct to 21 09 billion cubic meters while canadian sales slipped 4 1 pct to 48 09 billion cubic meters the federal agency said that in december oil production fell 4 0 pct to 7 73 mln cubic meters while exports rose 5 2 pct to 2 84 mln cubic meters and imports rose 12 3 pct to 2 1 mln cubic meters natural gas exports fell 16 3 pct in the month 2 51 billion cubic meters and canadian sales eased 10 2 pct to 5 25 billion cubic meters',\n",
              " 'coffee sugar and cocoa exchange names chairman the new york coffee sugar and cocoa exchange csce elected former first vice chairman to a two year term as chairman of the board of managers replacing previous chairman howard chairman since 1985 will remain a board member currently serves on the exchange board of managers as chairman of its appeals executive pension and political action committees the csce also elected charles executive vice president of shearson lehman bros as first vice chairman anthony vice president of woodhouse and was named second vice chairman and evans president of futures was elected treasurer']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "nEKPI4-oMooB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}