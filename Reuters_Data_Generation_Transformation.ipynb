{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fids_train = np.array([fid for fid in reuters.fileids() if fid.startswith('train')])\n",
    "fids_test = np.array([fid for fid in reuters.fileids() if fid.startswith('test')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_sents = lambda fids: (' '.join(sent) for fid in fids for sent in reuters.sents(fid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(gen_sents(fids_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import zip_longest\n",
    "def grouper(iterable, n, fillvalue=None):\n",
    "    \"Collect data into fixed-length chunks or blocks\"\n",
    "    args = [iter(iterable)] * n\n",
    "    return zip_longest(fillvalue=fillvalue, *args)\n",
    "\n",
    "class ReutersGenerator():\n",
    "    def __init__(self, max_seq_length=250, num_words=5000):\n",
    "        self.tok = Tokenizer(num_words=num_words)\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.num_words = num_words\n",
    "    \n",
    "    def _gen_sents(self, fids):\n",
    "        return (' '.join(sent) for fid in fids for sent in reuters.sents(fid))\n",
    "    \n",
    "    def fit(self, fid_startswith='train'):\n",
    "        fids = (fid for fid in reuters.fileids() if fid.startswith(fid_startswith))\n",
    "        self.tok.fit_on_texts(self._gen_sents(fids))\n",
    "        return self\n",
    "\n",
    "    def count(self, fid_startswith='train'):\n",
    "        fids = (fid for fid in reuters.fileids() if fid.startswith(fid_startswith))\n",
    "        return sum(1 for _ in self._gen_sents(fids))\n",
    "    \n",
    "    def inverse_transform(self, X):\n",
    "        return self.tok.sequences_to_texts(X)\n",
    "    \n",
    "    def generate_pairs(self, fid_startswith='train', bs=32, \n",
    "                         max_seq_len=250, forever=False, shuffle=True):\n",
    "        fids_in = np.array([fid for fid in reuters.fileids() if fid.startswith(fid_startswith)])\n",
    "        index = np.arange(fids_in.shape[0])\n",
    "        while True:\n",
    "            np.random.shuffle(index)\n",
    "            fids = fids_in[index]\n",
    "            sents = self._gen_sents(fids)\n",
    "            for batch in grouper(sents, bs):\n",
    "                seqs = self.tok.texts_to_sequences_generator(text for text in batch if text)\n",
    "                X = pad_sequences(list(seqs), self.max_seq_length)\n",
    "                yield X, to_categorical(X, self.num_words)\n",
    "            if not forever:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ReutersGenerator(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.ReutersGenerator at 0x1825c9278>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14439"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, X_hat = next(data.generate_pairs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 250)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 250, 10000)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"saudi output said at year low to help opec saudi arabian oil output has fallen to its lowest level in more than a year giving fresh evidence of the kingdom ' s determination to keep oil prices at 18 dlrs a barrel as agreed by opec last december oil industry sources said\",\n",
       " 'they said saudi output in the first eight days of march averaged 2 6 mln barrels per day bpd including oil from the neutral zone shared with kuwait compared to a february average of 3 5 mln bpd',\n",
       " \"they said saudi arabia was also selling oil from its crude oil stocks in tankers around the world which opec says must be towards a member ' s production quota\",\n",
       " \"saudi arabia ' s quota is 4 133 mln bpd\",\n",
       " 'the lower production levels indicated saudi arabia the world s largest oil exporter was insisting on getting opec official prices even at the cost of lower production the sources said',\n",
       " \"king fahd reiterated yesterday in an interview with reuters and the television news agency visnews the saudi commitment to opec ' s december pact to boost oil prices to an average 18 dlrs\",\n",
       " 'saudi arabia is completely sticking to opec decisions he said',\n",
       " \"the sources said the kingdom ' s exports from gulf ports averaged one mln bpd during the eight days ending last sunday down from a february average of 1 9 mln bpd\",\n",
       " 'they said saudi arabia was allowing production to fluctuate with lifting and was not trying to maintain artificially high levels by putting oil into storage',\n",
       " \"the kingdom ' s main buyers the four u s oil firms with past stakes in the national oil company mobil exxon texaco and chevron enjoy considerable flexibility in the timing and volume of their liftings but are bound to pay official prices the sources said\",\n",
       " 'spot market prices have firmed in the past two weeks but still remain below opec levels and major buyers have delayed liftings in the hope they would improve the sources said',\n",
       " 'they expected low early march output to pick up towards the end of the month as buyers sought to fulfill their contractual obligations',\n",
       " 'icco members accept buffer stock principles international cocoa organization icco producers and consumers accepted the principles of a compromise proposal on buffer stock rules as a basis for further negotiation delegates said',\n",
       " 'the buffer stock working group then asked icco executive director kobena erbynn who wrote up the draft compromise to out details of the principles with the assistance of a representative group of delegates they said',\n",
       " 'the working group broke up for the day into a smaller group of five producers and five consumers to discuss administrative rules and into the group headed by erbynn to hammer out buffer stock rules details delegates said',\n",
       " 'delegates said many differences of opinion still have to be out',\n",
       " 'whenever we start getting into details the one delegate said',\n",
       " 'erbynn is likely to present out details of the buffer stock rules proposal to the working group early tomorrow delegates said',\n",
       " 'the principles of the draft proposal included establishing an offer system for buffer stock purchases rather than a posted price system a limit to the amount of non icco member cocoa that can be bought and differentials to be paid for different varieties of cocoa comprising the buffer stock delegates said',\n",
       " \"union pacific lt unp closes venezuelan partnership union pacific corp said it has closed the previously announced 50 50 partnership with petroleos de venezuela sa venezuela ' s national oil company to own a 160 000 barrel per day refinery in corpus christi texas\",\n",
       " \"union pacific said the partnership called champlin refining co will acquire the refining and distribution system owned and operated by union pacific ' s champlin petroleum co subsidiary\",\n",
       " 'the venezuelan company also signed a 25 year feedstock agreement with the partnership to supply at least 140 000 barrels a day of venezuelan crude oil and naphtha at market related prices',\n",
       " 'u s securities group backs insider restraints the securities industry association backed a variety of restraints on insider trading and hostile corporate takeovers and asked congress to define insider trading in law',\n",
       " 'the industry trade association called on u s securities firms to take steps to protect sensitive corporate to guard against illegal trading by employees',\n",
       " 'the association also backed broad federal restrictions on a variety of tactics used in hostile corporate takeovers',\n",
       " 'but it said investment banking firms should be allowed to continue to engage in both arbitrage and merger and acquisition activities so long as those were kept separate',\n",
       " 'the in a report adopted yesterday by its board of directors backed a higher enforcement budget for the federal securities and exchange commission and called on u s stock exchanges to beef up their of member',\n",
       " 'the report said securities firms should be more in restricting sensitive information on a need to know basis',\n",
       " 'it said firms should train their employees to understand the need for confidentiality of market sensitive information',\n",
       " 'it said legislation to define insider trading should avoid expanding current law in a way that would the market',\n",
       " 'it said an insider trading definition should exempt a securities firm from liability for law violations by its employees unless the firm had in or was aware of the',\n",
       " 'in the mergers and acquisitions area the association advocated a ban on greenmail payments or poison pill takeover protection plans without prior shareholder approval']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.inverse_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ASIAN EXPORTERS FEAR DAMAGE FROM U . S .- JAPAN RIFT Mounting trade friction between the U . S . And Japan has raised fears among many of Asia ' s exporting nations that the row could inflict far - reaching economic damage , businessmen and officials said .\""
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(reuters.sents(reuters.fileids()[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement moving window approach: generate (n-gram (min < n < max), target)-pairs \n",
    "# and move by stride m, e.g. \"dieser text ist ein test .\" => [dieser text] -> ist,\n",
    "# [text ist ein] -> test (for m=1, 1 < n < 50)\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import reuters\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from itertools import zip_longest, islice\n",
    "\n",
    "tok = Tokenizer(filters='\"#$%&()*+-/<=>@[\\\\]^_`{|}~\\t\\n')\n",
    "tok.fit_on_texts(' '.join(word_tokenize(reuters.raw(fid))) for fid in reuters.fileids())\n",
    "sents = tok.texts_to_sequences_generator(\n",
    "    ' '.join(word_tokenize(reuters.raw(fid))) for fid in reuters.fileids())\n",
    "tokens = (tok for sent in sents for tok in sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: asian exporters\n",
      "TARGET: fear\n",
      "DATA: asian exporters fear\n",
      "TARGET: damage\n",
      "DATA: asian exporters fear damage\n",
      "TARGET: from\n",
      "DATA: exporters fear damage from\n",
      "TARGET: u.s.\n",
      "DATA: exporters fear damage from u.s.\n",
      "TARGET: japan\n",
      "DATA: fear damage from u.s. japan\n",
      "TARGET: rift\n",
      "DATA: damage from u.s. japan rift\n",
      "TARGET: mounting\n",
      "DATA: japan rift mounting\n",
      "TARGET: trade\n",
      "DATA: u.s. japan rift mounting trade\n",
      "TARGET: friction\n",
      "DATA: rift mounting trade friction\n",
      "TARGET: between\n",
      "DATA: trade friction between\n",
      "TARGET: the\n",
      "DATA: mounting trade friction between the\n",
      "TARGET: u.s.\n",
      "DATA: between the u.s.\n",
      "TARGET: and\n",
      "DATA: the u.s. and\n",
      "TARGET: japan\n",
      "DATA: the u.s. and japan\n",
      "TARGET: has\n",
      "DATA: and japan has\n",
      "TARGET: raised\n",
      "DATA: and japan has raised\n",
      "TARGET: fears\n",
      "DATA: and japan has raised fears\n",
      "TARGET: among\n",
      "DATA: japan has raised fears among\n",
      "TARGET: many\n",
      "DATA: fears among many\n",
      "TARGET: of\n",
      "DATA: fears among many of\n",
      "TARGET: asia\n",
      "DATA: among many of asia\n",
      "TARGET: 's\n",
      "DATA: of asia 's\n",
      "TARGET: exporting\n",
      "DATA: many of asia 's exporting\n",
      "TARGET: nations\n",
      "DATA: 's exporting nations\n",
      "TARGET: that\n",
      "DATA: asia 's exporting nations that\n",
      "TARGET: the\n",
      "DATA: 's exporting nations that the\n",
      "TARGET: row\n",
      "DATA: exporting nations that the row\n",
      "TARGET: could\n",
      "DATA: the row could\n",
      "TARGET: inflict\n",
      "DATA: row could inflict\n",
      "TARGET: far\n",
      "DATA: the row could inflict far\n",
      "TARGET: reaching\n",
      "DATA: could inflict far reaching\n",
      "TARGET: economic\n",
      "DATA: inflict far reaching economic\n",
      "TARGET: damage\n",
      "DATA: inflict far reaching economic damage\n",
      "TARGET: ,\n",
      "DATA: economic damage ,\n",
      "TARGET: businessmen\n",
      "DATA: reaching economic damage , businessmen\n",
      "TARGET: and\n",
      "DATA: damage , businessmen and\n",
      "TARGET: officials\n",
      "DATA: , businessmen and officials\n",
      "TARGET: said\n",
      "DATA: and officials said\n",
      "TARGET: .\n",
      "DATA: officials said .\n",
      "TARGET: they\n",
      "DATA: and officials said . they\n",
      "TARGET: told\n",
      "DATA: . they told\n",
      "TARGET: reuter\n",
      "DATA: they told reuter\n",
      "TARGET: correspondents\n",
      "DATA: told reuter correspondents\n",
      "TARGET: in\n",
      "DATA: told reuter correspondents in\n",
      "TARGET: asian\n",
      "DATA: told reuter correspondents in asian\n",
      "TARGET: capitals\n",
      "DATA: reuter correspondents in asian capitals\n",
      "TARGET: a\n",
      "DATA: asian capitals a\n",
      "TARGET: u.s.\n",
      "DATA: move against\n",
      "TARGET: japan\n",
      "DATA: move against japan\n",
      "TARGET: might\n"
     ]
    }
   ],
   "source": [
    "def grouper(iterable, n, fillvalue=None):\n",
    "    \"Collect data into fixed-length chunks or blocks\"\n",
    "    args = [iter(iterable)] * n\n",
    "    return zip_longest(fillvalue=fillvalue, *args)\n",
    "\n",
    "def generate_ngram_pairs(tokens, min_toks=2, max_toks=5, chunk_len=50):\n",
    "    chunks_of_toks = grouper(tokens, chunk_len)\n",
    "    for chunk in chunks_of_toks:\n",
    "        chunk = np.array(chunk)\n",
    "        for pred in range(min_toks, chunk_len):\n",
    "            n_toks = np.random.randint(min_toks, max_toks)\n",
    "            data = chunk[max(0, pred-n_toks-1):pred]\n",
    "            target = chunk[pred]\n",
    "            yield data, target\n",
    "            \n",
    "for data, target in islice(generate_ngram_pairs(tokens), 50):\n",
    "    print('DATA:', tok.sequences_to_texts([data])[0])\n",
    "    print('TARGET:', tok.sequences_to_texts([[target]])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
