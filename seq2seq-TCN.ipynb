{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq-TCN.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "W1_uV8WoFXQu",
        "colab_type": "code",
        "outputId": "16b64702-a3b3-4111-a78a-bbe92027358d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!mkdir -p /content/drive/My\\ Drive/nn_output"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xscbWz8wGH0J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "OUTPUTDIR='/content/drive/My Drive/nn_output'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jrCPRQxBFJqP",
        "colab_type": "code",
        "outputId": "96f637f7-3df6-47c5-9104-545954b4c0d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install keras-TCN\n",
        "\n",
        "from keras.layers import (Bidirectional, Dense, Embedding, Input, Lambda, InputLayer, Reshape\n",
        "                          , LSTM, RepeatVector, TimeDistributed)\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from tcn import TCN\n",
        "from keras.utils import to_categorical\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "from nltk.corpus import reuters\n",
        "from itertools import chain\n",
        "import nltk\n",
        "nltk.download('reuters')\n",
        "nltk.download('punkt')\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import os.path\n",
        "import glob"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-TCN\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/bc/dcbdc24d80229022333150f42ff88ddf4c6793568f711a0d6fc1e83b102e/keras_tcn-2.3.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-TCN) (2.2.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-TCN) (1.14.6)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-TCN) (1.0.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-TCN) (1.0.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-TCN) (1.11.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-TCN) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-TCN) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-TCN) (2.8.0)\n",
            "Installing collected packages: keras-TCN\n",
            "Successfully installed keras-TCN-2.3.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4MSNGaUfsChk",
        "colab_type": "code",
        "outputId": "2b523e36-41e6-4dcc-ba1d-b18b49f6c2b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4199
        }
      },
      "cell_type": "code",
      "source": [
        "MAX_SEQUENCE_LEN = 250\n",
        "MAX_NUM_WORDS = 10000\n",
        "\n",
        "kernel_size = 3\n",
        "n_dilations = 8\n",
        "n_hidden = 256\n",
        "embedding_size = 100\n",
        "dropout=0.4\n",
        "\n",
        "input_layer = Input(shape=(MAX_SEQUENCE_LEN,))\n",
        "encoder = Embedding(MAX_NUM_WORDS, embedding_size)(input_layer)\n",
        "encoder = TCN(name='latent', return_sequences=False,\n",
        "              kernel_size=kernel_size,\n",
        "              dilations=[2**n for n in range(n_dilations)],\n",
        "              nb_filters=n_hidden,\n",
        "              nb_stacks=1,\n",
        "              dropout_rate=dropout)(encoder)\n",
        "decoder = RepeatVector(MAX_SEQUENCE_LEN, name='decoder')(encoder)\n",
        "decoder = TCN(return_sequences=True,\n",
        "              kernel_size=kernel_size,\n",
        "              dilations=[2**n for n in range(n_dilations)],\n",
        "              nb_filters=n_hidden,\n",
        "              nb_stacks=1,\n",
        "              dropout_rate=dropout)(decoder)\n",
        "output_layer = TimeDistributed(Dense(MAX_NUM_WORDS, activation='softmax'))(decoder)\n",
        "model = Model(input_layer, output_layer)\n",
        "optimizer = optimizers.Adam(lr=0.002, clipnorm=0.4)\n",
        "model.compile(optimizer=optimizer, metrics=['accuracy'], loss='categorical_crossentropy')\n",
        "print(model.summary())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 250)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 250, 100)     1000000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "latent_initial_conv (Conv1D)    (None, 250, 256)     25856       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "latent_d_causal_conv_1_tanh_s0  (None, 250, 256)     196864      latent_initial_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 250, 256)     0           latent_d_causal_conv_1_tanh_s0[0]\n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 250, 256)     0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "latent_spatial_dropout1d_1_s0_0 (None, 250, 256)     0           lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 250, 256)     65792       latent_spatial_dropout1d_1_s0_0.4\n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 250, 256)     0           latent_initial_conv[0][0]        \n",
            "                                                                 conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "latent_d_causal_conv_2_tanh_s0  (None, 250, 256)     196864      add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 250, 256)     0           latent_d_causal_conv_2_tanh_s0[0]\n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 250, 256)     0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "latent_spatial_dropout1d_2_s0_0 (None, 250, 256)     0           lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 250, 256)     65792       latent_spatial_dropout1d_2_s0_0.4\n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 250, 256)     0           add_1[0][0]                      \n",
            "                                                                 conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "latent_d_causal_conv_4_tanh_s0  (None, 250, 256)     196864      add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 250, 256)     0           latent_d_causal_conv_4_tanh_s0[0]\n",
            "__________________________________________________________________________________________________\n",
            "lambda_3 (Lambda)               (None, 250, 256)     0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "latent_spatial_dropout1d_4_s0_0 (None, 250, 256)     0           lambda_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 250, 256)     65792       latent_spatial_dropout1d_4_s0_0.4\n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 250, 256)     0           add_2[0][0]                      \n",
            "                                                                 conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "latent_d_causal_conv_8_tanh_s0  (None, 250, 256)     196864      add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 250, 256)     0           latent_d_causal_conv_8_tanh_s0[0]\n",
            "__________________________________________________________________________________________________\n",
            "lambda_4 (Lambda)               (None, 250, 256)     0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "latent_spatial_dropout1d_8_s0_0 (None, 250, 256)     0           lambda_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 250, 256)     65792       latent_spatial_dropout1d_8_s0_0.4\n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 250, 256)     0           add_3[0][0]                      \n",
            "                                                                 conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "latent_d_causal_conv_16_tanh_s0 (None, 250, 256)     196864      add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 250, 256)     0           latent_d_causal_conv_16_tanh_s0[0\n",
            "__________________________________________________________________________________________________\n",
            "lambda_5 (Lambda)               (None, 250, 256)     0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "latent_spatial_dropout1d_16_s0_ (None, 250, 256)     0           lambda_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 250, 256)     65792       latent_spatial_dropout1d_16_s0_0.\n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 250, 256)     0           add_4[0][0]                      \n",
            "                                                                 conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "latent_d_causal_conv_32_tanh_s0 (None, 250, 256)     196864      add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 250, 256)     0           latent_d_causal_conv_32_tanh_s0[0\n",
            "__________________________________________________________________________________________________\n",
            "lambda_6 (Lambda)               (None, 250, 256)     0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "latent_spatial_dropout1d_32_s0_ (None, 250, 256)     0           lambda_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 250, 256)     65792       latent_spatial_dropout1d_32_s0_0.\n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 250, 256)     0           add_5[0][0]                      \n",
            "                                                                 conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "latent_d_causal_conv_64_tanh_s0 (None, 250, 256)     196864      add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 250, 256)     0           latent_d_causal_conv_64_tanh_s0[0\n",
            "__________________________________________________________________________________________________\n",
            "lambda_7 (Lambda)               (None, 250, 256)     0           activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "latent_spatial_dropout1d_64_s0_ (None, 250, 256)     0           lambda_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_7 (Conv1D)               (None, 250, 256)     65792       latent_spatial_dropout1d_64_s0_0.\n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 250, 256)     0           add_6[0][0]                      \n",
            "                                                                 conv1d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "latent_d_causal_conv_128_tanh_s (None, 250, 256)     196864      add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 250, 256)     0           latent_d_causal_conv_128_tanh_s0[\n",
            "__________________________________________________________________________________________________\n",
            "lambda_8 (Lambda)               (None, 250, 256)     0           activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "latent_spatial_dropout1d_128_s0 (None, 250, 256)     0           lambda_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_8 (Conv1D)               (None, 250, 256)     65792       latent_spatial_dropout1d_128_s0_0\n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 250, 256)     0           conv1d_1[0][0]                   \n",
            "                                                                 conv1d_2[0][0]                   \n",
            "                                                                 conv1d_3[0][0]                   \n",
            "                                                                 conv1d_4[0][0]                   \n",
            "                                                                 conv1d_5[0][0]                   \n",
            "                                                                 conv1d_6[0][0]                   \n",
            "                                                                 conv1d_7[0][0]                   \n",
            "                                                                 conv1d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 250, 256)     0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_9 (Lambda)               (None, 256)          0           activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder (RepeatVector)          (None, 250, 256)     0           lambda_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tcn_initial_conv (Conv1D)       (None, 250, 256)     65792       decoder[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tcn_d_causal_conv_1_tanh_s0 (Co (None, 250, 256)     196864      tcn_initial_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 250, 256)     0           tcn_d_causal_conv_1_tanh_s0[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "lambda_10 (Lambda)              (None, 250, 256)     0           activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tcn_spatial_dropout1d_1_s0_0.40 (None, 250, 256)     0           lambda_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_9 (Conv1D)               (None, 250, 256)     65792       tcn_spatial_dropout1d_1_s0_0.4000\n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 250, 256)     0           tcn_initial_conv[0][0]           \n",
            "                                                                 conv1d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tcn_d_causal_conv_2_tanh_s0 (Co (None, 250, 256)     196864      add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 250, 256)     0           tcn_d_causal_conv_2_tanh_s0[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "lambda_11 (Lambda)              (None, 250, 256)     0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tcn_spatial_dropout1d_2_s0_0.40 (None, 250, 256)     0           lambda_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_10 (Conv1D)              (None, 250, 256)     65792       tcn_spatial_dropout1d_2_s0_0.4000\n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 250, 256)     0           add_10[0][0]                     \n",
            "                                                                 conv1d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tcn_d_causal_conv_4_tanh_s0 (Co (None, 250, 256)     196864      add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 250, 256)     0           tcn_d_causal_conv_4_tanh_s0[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "lambda_12 (Lambda)              (None, 250, 256)     0           activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tcn_spatial_dropout1d_4_s0_0.40 (None, 250, 256)     0           lambda_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_11 (Conv1D)              (None, 250, 256)     65792       tcn_spatial_dropout1d_4_s0_0.4000\n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 250, 256)     0           add_11[0][0]                     \n",
            "                                                                 conv1d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tcn_d_causal_conv_8_tanh_s0 (Co (None, 250, 256)     196864      add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 250, 256)     0           tcn_d_causal_conv_8_tanh_s0[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "lambda_13 (Lambda)              (None, 250, 256)     0           activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tcn_spatial_dropout1d_8_s0_0.40 (None, 250, 256)     0           lambda_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_12 (Conv1D)              (None, 250, 256)     65792       tcn_spatial_dropout1d_8_s0_0.4000\n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 250, 256)     0           add_12[0][0]                     \n",
            "                                                                 conv1d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tcn_d_causal_conv_16_tanh_s0 (C (None, 250, 256)     196864      add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 250, 256)     0           tcn_d_causal_conv_16_tanh_s0[0][0\n",
            "__________________________________________________________________________________________________\n",
            "lambda_14 (Lambda)              (None, 250, 256)     0           activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tcn_spatial_dropout1d_16_s0_0.4 (None, 250, 256)     0           lambda_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_13 (Conv1D)              (None, 250, 256)     65792       tcn_spatial_dropout1d_16_s0_0.400\n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 250, 256)     0           add_13[0][0]                     \n",
            "                                                                 conv1d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tcn_d_causal_conv_32_tanh_s0 (C (None, 250, 256)     196864      add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 250, 256)     0           tcn_d_causal_conv_32_tanh_s0[0][0\n",
            "__________________________________________________________________________________________________\n",
            "lambda_15 (Lambda)              (None, 250, 256)     0           activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tcn_spatial_dropout1d_32_s0_0.4 (None, 250, 256)     0           lambda_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_14 (Conv1D)              (None, 250, 256)     65792       tcn_spatial_dropout1d_32_s0_0.400\n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 250, 256)     0           add_14[0][0]                     \n",
            "                                                                 conv1d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tcn_d_causal_conv_64_tanh_s0 (C (None, 250, 256)     196864      add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 250, 256)     0           tcn_d_causal_conv_64_tanh_s0[0][0\n",
            "__________________________________________________________________________________________________\n",
            "lambda_16 (Lambda)              (None, 250, 256)     0           activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tcn_spatial_dropout1d_64_s0_0.4 (None, 250, 256)     0           lambda_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_15 (Conv1D)              (None, 250, 256)     65792       tcn_spatial_dropout1d_64_s0_0.400\n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 250, 256)     0           add_15[0][0]                     \n",
            "                                                                 conv1d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tcn_d_causal_conv_128_tanh_s0 ( (None, 250, 256)     196864      add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 250, 256)     0           tcn_d_causal_conv_128_tanh_s0[0][\n",
            "__________________________________________________________________________________________________\n",
            "lambda_17 (Lambda)              (None, 250, 256)     0           activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tcn_spatial_dropout1d_128_s0_0. (None, 250, 256)     0           lambda_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_16 (Conv1D)              (None, 250, 256)     65792       tcn_spatial_dropout1d_128_s0_0.40\n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 250, 256)     0           conv1d_9[0][0]                   \n",
            "                                                                 conv1d_10[0][0]                  \n",
            "                                                                 conv1d_11[0][0]                  \n",
            "                                                                 conv1d_12[0][0]                  \n",
            "                                                                 conv1d_13[0][0]                  \n",
            "                                                                 conv1d_14[0][0]                  \n",
            "                                                                 conv1d_15[0][0]                  \n",
            "                                                                 conv1d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 250, 256)     0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 250, 10000)   2570000     activation_18[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 7,864,144\n",
            "Trainable params: 7,864,144\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k5lh2ZJRsChy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from itertools import zip_longest\n",
        "def grouper(iterable, n, fillvalue=None):\n",
        "    \"Collect data into fixed-length chunks or blocks\"\n",
        "    args = [iter(iterable)] * n\n",
        "    return zip_longest(fillvalue=fillvalue, *args)\n",
        "\n",
        "class ReutersGenerator():\n",
        "    def __init__(self, max_seq_length=250, num_words=5000):\n",
        "        self.tok = Tokenizer(num_words=num_words)\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.num_words = num_words\n",
        "    \n",
        "    def _gen_sents(self, fids):\n",
        "        return (' '.join(sent) for fid in fids for sent in reuters.sents(fid))\n",
        "    \n",
        "    def fit(self, fid_startswith='train'):\n",
        "        fids = (fid for fid in reuters.fileids() if fid.startswith(fid_startswith))\n",
        "        self.tok.fit_on_texts(self._gen_sents(fids))\n",
        "        return self\n",
        "\n",
        "    def count(self, fid_startswith='train'):\n",
        "        fids = (fid for fid in reuters.fileids() if fid.startswith(fid_startswith))\n",
        "        return sum(1 for _ in self._gen_sents(fids))\n",
        "    \n",
        "    def inverse_transform(self, X):\n",
        "        return self.tok.sequences_to_texts(X)\n",
        "    \n",
        "    def generate_pairs(self, fid_startswith='train', bs=32, \n",
        "                         max_seq_len=250, forever=True, shuffle=True):\n",
        "        fids_in = np.array([fid for fid in reuters.fileids() if fid.startswith(fid_startswith)])\n",
        "        index = np.arange(fids_in.shape[0])\n",
        "        while True:\n",
        "            np.random.shuffle(index)\n",
        "            fids = fids_in[index]\n",
        "            sents = self._gen_sents(fids)\n",
        "            for batch in grouper(sents, bs):\n",
        "                seqs = self.tok.texts_to_sequences_generator(text for text in batch if text)\n",
        "                X = pad_sequences(list(seqs), self.max_seq_length)\n",
        "                yield X, to_categorical(X, self.num_words)\n",
        "            if not forever:\n",
        "                break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SSZgXz1tHKqk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reuters_gen = ReutersGenerator(\n",
        "    num_words=MAX_NUM_WORDS, max_seq_length=MAX_SEQUENCE_LEN).fit()\n",
        "n_train = reuters_gen.count('train')\n",
        "#n_test = reuters_gen.count('test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1MR8JitksCiH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "basename = 'seq2seq-TCN-model-small'\n",
        "outfname = os.path.join(\n",
        "    OUTPUTDIR,\n",
        "    basename + '-ep{epoch:02d}.hdf5')\n",
        "cp = ModelCheckpoint(\n",
        "    outfname,\n",
        "    save_best_only=False,\n",
        "    save_weights_only=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L7AgCeZ3E_8D",
        "colab_type": "code",
        "outputId": "e796eb10-c5c2-411d-c9d1-5508429fbecc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "TRAIN_MODEL = True\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 20\n",
        "\n",
        "if TRAIN_MODEL:\n",
        "  history = model.fit_generator(reuters_gen.generate_pairs('train', bs=BATCH_SIZE),\n",
        "      #validation_data=reuters_gen.generate_pairs('test', bs=BATCH_SIZE),\n",
        "      steps_per_epoch=n_train//BATCH_SIZE,\n",
        "      #validation_steps=n_test//BATCH_SIZE,\n",
        "      epochs=EPOCHS, shuffle=True, callbacks=[cp])\n",
        "else:\n",
        "  list_of_files = glob.glob(os.path.join(OUTPUTDIR, basename + '*.hdf5'))\n",
        "  list_of_files = sorted(list_of_files, key=os.path.getctime)\n",
        "  assert(len(list_of_files) > 0)\n",
        "  model = load_model(list_of_files[-1])\n",
        "  print('Loaded model from \\'%s\\'' % list_of_files[-1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model '/content/drive/My Drive/nn_output/seq2seq-TCN-model-small-ep20.hdf5'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VsIoTBfwnnqT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_train_hat = next(reuters_gen.generate_pairs('train'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_V9D4-TTsCiM",
        "colab_type": "code",
        "outputId": "84a4cb24-16c5-46e7-a1bf-1244c2ae2ab5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "cell_type": "code",
      "source": [
        "reuters_gen.inverse_transform(np.argmax(model.predict(X_train[:20], verbose=1), axis=2))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r20/20 [==============================] - 4s 199ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lt year net net net net net net net net net net vs vs vs vs mln mln mln mln vs vs vs mln vs vs vs mln mln in mths',\n",
              " 'company company 1986 1986 net net vs mln mln mln mln mln mln mln 1986 1986 1986 1986 and mln mln vs vs vs mln mln',\n",
              " 'says the the the the the the the the the the the the the the to to to to to to to the the the the the to the the the the the the dealers said',\n",
              " 'the the the the the the the the the to to to to to the the the the the the to to the the the the the the the the to to pct they said',\n",
              " 'the the the the the the the the the the the to to to to to to to to to to the the the to pct pct pct pct the dealers said',\n",
              " 'the the the the the the to to billion billion billion billion a the the the the the the the the the of below yen',\n",
              " 'lt lt lt lt lt lt lt lt lt lt lt lt to to to to to to lt s s s s the the s s s s the to to about 500 mln stg',\n",
              " 'the said the to the the the and and and and and the texas',\n",
              " 'he said said said it to to to the the the the the to to to the and and and the the the company',\n",
              " \"the the the the the the said said the the the the to to to the the the the the the ' ' and and and lt lt lt inc\",\n",
              " 'he said said said the the to to to to to the price',\n",
              " \"the said said said said the the the the the the the the the the the the the the the the the the ' ' the the the to the board\",\n",
              " 'the said said said the the to to to to the statement',\n",
              " 'u s',\n",
              " 'exporters grants 350 tonnes tonnes corn corn corn unknown corn corn 1986 87',\n",
              " 'u s',\n",
              " 'exporters grants 350 tonnes tonnes corn corn corn unknown corn corn 1986 87',\n",
              " 'lt lt shr shr shr cts cts cts cts cts vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs vs mln note note note note note note note note 000 mln mln mln dlrs dlrs dlrs dlrs in share',\n",
              " \"u ' ' ' ' ' legislation legislation legislation ' ' ' ' ' legislation legislation to to to u s s s s s rostenkowski rostenkowski said\",\n",
              " 'the to to to to to to to to to to to to to to to to to to to to the the the the the the the the to to to the the s s the the the a s secretary lyng said']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "koH_AU6hsCiT",
        "colab_type": "code",
        "outputId": "76444f30-ea92-4740-a40e-11a12c52154e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "cell_type": "code",
      "source": [
        "reuters_gen.inverse_transform(X_train[:20])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lt to charge corp said it to charges of to the social security administration and agreed to pay 1 2 mln dlrs in and costs to the u s government',\n",
              " 'the company also reached agreements in principle for an 8 1 mln dlr settlement of class action law',\n",
              " \"about 2 9 mln dlrs of the class action settlement will be provided by ' s insurance carrier\",\n",
              " 'the settlement is contingent on court approval after notice to class members it said',\n",
              " 'the case settlement all charges including and statement except for to which',\n",
              " \"the settlement includes the lifting of the government ' s suspension the of the federal civil claims suit and all charges against the individuals\",\n",
              " 'of the 2 9 mln dlrs the insurance carrier will provide for the civil settlement 750 000 dlrs will go to settle a lawsuit',\n",
              " 'for the year ended december 31 reported a net loss of 38 5 mln dlrs',\n",
              " 'the year end results include an 8 0 mln dlrs provision for future legal and or settlement costs to cover the civil and announced today',\n",
              " 'also said it named as president and chief executive officer robert who resigned as chairman and chief executive officer as part of the settlement of the',\n",
              " 'formerly served as executive vice president and chief operating officer',\n",
              " 'the company also said that due to the sluggish it does not expect to be profitable in the first quarter but is optimistic about the outlook for the year',\n",
              " 'for the first quarter of 1986 the company reported net income of 875 000 dlrs on sales of 66 0 mln dlrs',\n",
              " 'was among five executives who were charged along with three former officers in a 1985 federal from a 115 mln contract awarded to in 1981 to build a computer network for the social security administration',\n",
              " 'the were accused of to government officials and the social security administration',\n",
              " 'and other were also charged with providing testimony and justice during a securities and exchange commission investigation',\n",
              " 'under the settlement announced today federal agreed to all charges against and three other under a one year agreement',\n",
              " 'the charges would then be dropped if the successfully complete the period',\n",
              " 'details of the requirements in the agreement were not immediately available',\n",
              " 'and lt to make acquisition and inc said it has agreed to acquire electric parts distributor b and w electric supply co for an undisclosed amount of cash']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "WcYZnmYiG1Tw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pXd7v4MBG1WW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def iter_labels(selection='train'):\n",
        "    for fid in reuters.fileids():\n",
        "        if fid.startswith(selection):\n",
        "            for sent in reuters.sents(fid):\n",
        "                yield reuters.categories(fid)\n",
        "labels_train = np.array(list(iter_labels('train')))\n",
        "labels_test = np.array(list(iter_labels('test')))\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer().fit(labels_train)\n",
        "y_train = mlb.transform(labels_train)\n",
        "y_test = mlb.transform(labels_test)\n",
        "\n",
        "def iter_sents(selection='train'):\n",
        "    for fid in reuters.fileids():\n",
        "        if fid.startswith(selection):\n",
        "            for sent in reuters.sents(fid):\n",
        "                yield \" \".join(sent)\n",
        "data_train = np.array(list(iter_sents('train')))\n",
        "data_test = np.array(list(iter_sents('test')))\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer.fit_on_texts(data_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(data_train)\n",
        "X_test = tokenizer.texts_to_sequences(data_test)\n",
        "\n",
        "X_train = pad_sequences(X_train, MAX_SEQUENCE_LEN)\n",
        "X_test = pad_sequences(X_test, MAX_SEQUENCE_LEN)\n",
        "\n",
        "def data_generator(X_in, batch_size=32, shuffle=True, repeat=True):\n",
        "    index = np.arange(X_in.shape[0])\n",
        "    while True:\n",
        "        np.random.shuffle(index)\n",
        "        X = X_in[index]\n",
        "        n = X.shape[0]//batch_size\n",
        "        for chunk in np.split(X[:n*batch_size], n):\n",
        "            yield chunk, to_categorical(chunk, MAX_NUM_WORDS)\n",
        "        rest = X[n*batch_size:]\n",
        "        if rest.shape[0]:\n",
        "            yield rest, to_categorical(rest, MAX_NUM_WORDS)\n",
        "        if not repeat:\n",
        "            break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_UemOL34sCiY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_enc = Model(input_layer, encoder)\n",
        "vecs = model_enc.predict(X_hat[:1000], verbose=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wekWSy1nsCic",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "vecs_reduced = TSNE().fit_transform(vecs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M74X2ZjasCig",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "categories = [(cat, len(reuters.fileids(categories=cat))) for cat in reuters.categories()]\n",
        "topn = [cat for cat, _ in sorted(categories, key=lambda x: -x[1])[:10]]\n",
        "\n",
        "indexes = []\n",
        "for cat in topn:\n",
        "    index = []\n",
        "    for pos, cats in enumerate(labels_train[:1000]):\n",
        "        if cat in cats:\n",
        "            index.append(pos)\n",
        "    indexes.append((cat, index))\n",
        "\n",
        "for cat, index in indexes:\n",
        "    plt.scatter(vecs_reduced[index,0], vecs_reduced[index,1], label=cat)\n",
        "plt.legend(bbox_to_anchor=(1, 1.01))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0AsvOddQsCio",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}