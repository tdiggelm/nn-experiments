{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq-TCN.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "W1_uV8WoFXQu",
        "colab_type": "code",
        "outputId": "4a31388d-4287-4e9c-97c4-4b983091a462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!mkdir -p /content/drive/My\\ Drive/nn_output"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xscbWz8wGH0J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "OUTPUTDIR='/content/drive/My Drive/nn_output'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jrCPRQxBFJqP",
        "colab_type": "code",
        "outputId": "abe83e92-de91-47bc-d061-1417c5837f22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install keras-TCN\n",
        "\n",
        "from keras.layers import (Bidirectional, Dense, Embedding, Input, Lambda, InputLayer, Reshape\n",
        "                          , LSTM, RepeatVector, TimeDistributed)\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from tcn import TCN\n",
        "from keras.utils import to_categorical\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "from nltk.corpus import reuters\n",
        "from itertools import chain\n",
        "import nltk\n",
        "nltk.download('reuters')\n",
        "nltk.download('punkt')\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import os.path\n",
        "import glob"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-TCN\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/bc/dcbdc24d80229022333150f42ff88ddf4c6793568f711a0d6fc1e83b102e/keras_tcn-2.3.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-TCN) (1.14.6)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-TCN) (2.2.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-TCN) (1.0.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-TCN) (1.11.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-TCN) (1.0.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-TCN) (2.8.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-TCN) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-TCN) (3.13)\n",
            "Installing collected packages: keras-TCN\n",
            "Successfully installed keras-TCN-2.3.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4MSNGaUfsChk",
        "colab_type": "code",
        "outputId": "d0851e2c-01a4-4ed1-89ee-183aaeb5989f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4199
        }
      },
      "cell_type": "code",
      "source": [
        "MAX_SEQUENCE_LEN = 250\n",
        "MAX_NUM_WORDS = 10000\n",
        "\n",
        "kernel_size = 3\n",
        "n_dilations = 8\n",
        "n_hidden = 256\n",
        "embedding_size = 100\n",
        "dropout=0.4\n",
        "\n",
        "input_layer = Input(shape=(MAX_SEQUENCE_LEN,))\n",
        "encoder = Embedding(MAX_NUM_WORDS, embedding_size)(input_layer)\n",
        "encoder = TCN(name='latent', return_sequences=False,\n",
        "              kernel_size=kernel_size,\n",
        "              dilations=[2**n for n in range(n_dilations)],\n",
        "              nb_filters=n_hidden,\n",
        "              nb_stacks=1,\n",
        "              dropout_rate=dropout)(encoder)\n",
        "decoder = RepeatVector(MAX_SEQUENCE_LEN, name='decoder')(encoder)\n",
        "decoder = TCN(return_sequences=True,\n",
        "              kernel_size=kernel_size,\n",
        "              dilations=[2**n for n in range(n_dilations)],\n",
        "              nb_filters=n_hidden,\n",
        "              nb_stacks=1,\n",
        "              dropout_rate=dropout)(decoder)\n",
        "output_layer = TimeDistributed(Dense(MAX_NUM_WORDS, activation='softmax'))(decoder)\n",
        "model = Model(input_layer, output_layer)\n",
        "optimizer = optimizers.Adam(lr=0.002, clipnorm=0.4)\n",
        "model.compile(optimizer=optimizer, metrics=['accuracy'], loss='categorical_crossentropy')\n",
        "print(model.summary())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_11 (InputLayer)           (None, 250)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_11 (Embedding)        (None, 250, 100)     1000000     input_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "latent_initial_conv (Conv1D)    (None, 250, 256)     25856       embedding_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "latent_d_causal_conv_1_tanh_s0  (None, 250, 256)     196864      latent_initial_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 250, 256)     0           latent_d_causal_conv_1_tanh_s0[0]\n",
            "__________________________________________________________________________________________________\n",
            "lambda_163 (Lambda)             (None, 250, 256)     0           activation_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "latent_spatial_dropout1d_1_s0_0 (None, 250, 256)     0           lambda_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_153 (Conv1D)             (None, 250, 256)     65792       latent_spatial_dropout1d_1_s0_0.4\n",
            "__________________________________________________________________________________________________\n",
            "add_172 (Add)                   (None, 250, 256)     0           latent_initial_conv[0][0]        \n",
            "                                                                 conv1d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "latent_d_causal_conv_2_tanh_s0  (None, 250, 256)     196864      add_172[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 250, 256)     0           latent_d_causal_conv_2_tanh_s0[0]\n",
            "__________________________________________________________________________________________________\n",
            "lambda_164 (Lambda)             (None, 250, 256)     0           activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "latent_spatial_dropout1d_2_s0_0 (None, 250, 256)     0           lambda_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_154 (Conv1D)             (None, 250, 256)     65792       latent_spatial_dropout1d_2_s0_0.4\n",
            "__________________________________________________________________________________________________\n",
            "add_173 (Add)                   (None, 250, 256)     0           add_172[0][0]                    \n",
            "                                                                 conv1d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "latent_d_causal_conv_4_tanh_s0  (None, 250, 256)     196864      add_173[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 250, 256)     0           latent_d_causal_conv_4_tanh_s0[0]\n",
            "__________________________________________________________________________________________________\n",
            "lambda_165 (Lambda)             (None, 250, 256)     0           activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "latent_spatial_dropout1d_4_s0_0 (None, 250, 256)     0           lambda_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_155 (Conv1D)             (None, 250, 256)     65792       latent_spatial_dropout1d_4_s0_0.4\n",
            "__________________________________________________________________________________________________\n",
            "add_174 (Add)                   (None, 250, 256)     0           add_173[0][0]                    \n",
            "                                                                 conv1d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "latent_d_causal_conv_8_tanh_s0  (None, 250, 256)     196864      add_174[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 250, 256)     0           latent_d_causal_conv_8_tanh_s0[0]\n",
            "__________________________________________________________________________________________________\n",
            "lambda_166 (Lambda)             (None, 250, 256)     0           activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "latent_spatial_dropout1d_8_s0_0 (None, 250, 256)     0           lambda_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_156 (Conv1D)             (None, 250, 256)     65792       latent_spatial_dropout1d_8_s0_0.4\n",
            "__________________________________________________________________________________________________\n",
            "add_175 (Add)                   (None, 250, 256)     0           add_174[0][0]                    \n",
            "                                                                 conv1d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "latent_d_causal_conv_16_tanh_s0 (None, 250, 256)     196864      add_175[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 250, 256)     0           latent_d_causal_conv_16_tanh_s0[0\n",
            "__________________________________________________________________________________________________\n",
            "lambda_167 (Lambda)             (None, 250, 256)     0           activation_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "latent_spatial_dropout1d_16_s0_ (None, 250, 256)     0           lambda_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_157 (Conv1D)             (None, 250, 256)     65792       latent_spatial_dropout1d_16_s0_0.\n",
            "__________________________________________________________________________________________________\n",
            "add_176 (Add)                   (None, 250, 256)     0           add_175[0][0]                    \n",
            "                                                                 conv1d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "latent_d_causal_conv_32_tanh_s0 (None, 250, 256)     196864      add_176[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 250, 256)     0           latent_d_causal_conv_32_tanh_s0[0\n",
            "__________________________________________________________________________________________________\n",
            "lambda_168 (Lambda)             (None, 250, 256)     0           activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "latent_spatial_dropout1d_32_s0_ (None, 250, 256)     0           lambda_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_158 (Conv1D)             (None, 250, 256)     65792       latent_spatial_dropout1d_32_s0_0.\n",
            "__________________________________________________________________________________________________\n",
            "add_177 (Add)                   (None, 250, 256)     0           add_176[0][0]                    \n",
            "                                                                 conv1d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "latent_d_causal_conv_64_tanh_s0 (None, 250, 256)     196864      add_177[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 250, 256)     0           latent_d_causal_conv_64_tanh_s0[0\n",
            "__________________________________________________________________________________________________\n",
            "lambda_169 (Lambda)             (None, 250, 256)     0           activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "latent_spatial_dropout1d_64_s0_ (None, 250, 256)     0           lambda_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_159 (Conv1D)             (None, 250, 256)     65792       latent_spatial_dropout1d_64_s0_0.\n",
            "__________________________________________________________________________________________________\n",
            "add_178 (Add)                   (None, 250, 256)     0           add_177[0][0]                    \n",
            "                                                                 conv1d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "latent_d_causal_conv_128_tanh_s (None, 250, 256)     196864      add_178[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 250, 256)     0           latent_d_causal_conv_128_tanh_s0[\n",
            "__________________________________________________________________________________________________\n",
            "lambda_170 (Lambda)             (None, 250, 256)     0           activation_179[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "latent_spatial_dropout1d_128_s0 (None, 250, 256)     0           lambda_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_160 (Conv1D)             (None, 250, 256)     65792       latent_spatial_dropout1d_128_s0_0\n",
            "__________________________________________________________________________________________________\n",
            "add_180 (Add)                   (None, 250, 256)     0           conv1d_153[0][0]                 \n",
            "                                                                 conv1d_154[0][0]                 \n",
            "                                                                 conv1d_155[0][0]                 \n",
            "                                                                 conv1d_156[0][0]                 \n",
            "                                                                 conv1d_157[0][0]                 \n",
            "                                                                 conv1d_158[0][0]                 \n",
            "                                                                 conv1d_159[0][0]                 \n",
            "                                                                 conv1d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 250, 256)     0           add_180[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_171 (Lambda)             (None, 256)          0           activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder (RepeatVector)          (None, 250, 256)     0           lambda_171[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tcn_initial_conv (Conv1D)       (None, 250, 256)     65792       decoder[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tcn_d_causal_conv_1_tanh_s0 (Co (None, 250, 256)     196864      tcn_initial_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 250, 256)     0           tcn_d_causal_conv_1_tanh_s0[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "lambda_172 (Lambda)             (None, 250, 256)     0           activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tcn_spatial_dropout1d_1_s0_0.40 (None, 250, 256)     0           lambda_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_161 (Conv1D)             (None, 250, 256)     65792       tcn_spatial_dropout1d_1_s0_0.4000\n",
            "__________________________________________________________________________________________________\n",
            "add_181 (Add)                   (None, 250, 256)     0           tcn_initial_conv[0][0]           \n",
            "                                                                 conv1d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tcn_d_causal_conv_2_tanh_s0 (Co (None, 250, 256)     196864      add_181[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 250, 256)     0           tcn_d_causal_conv_2_tanh_s0[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "lambda_173 (Lambda)             (None, 250, 256)     0           activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tcn_spatial_dropout1d_2_s0_0.40 (None, 250, 256)     0           lambda_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_162 (Conv1D)             (None, 250, 256)     65792       tcn_spatial_dropout1d_2_s0_0.4000\n",
            "__________________________________________________________________________________________________\n",
            "add_182 (Add)                   (None, 250, 256)     0           add_181[0][0]                    \n",
            "                                                                 conv1d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tcn_d_causal_conv_4_tanh_s0 (Co (None, 250, 256)     196864      add_182[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 250, 256)     0           tcn_d_causal_conv_4_tanh_s0[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "lambda_174 (Lambda)             (None, 250, 256)     0           activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tcn_spatial_dropout1d_4_s0_0.40 (None, 250, 256)     0           lambda_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_163 (Conv1D)             (None, 250, 256)     65792       tcn_spatial_dropout1d_4_s0_0.4000\n",
            "__________________________________________________________________________________________________\n",
            "add_183 (Add)                   (None, 250, 256)     0           add_182[0][0]                    \n",
            "                                                                 conv1d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tcn_d_causal_conv_8_tanh_s0 (Co (None, 250, 256)     196864      add_183[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 250, 256)     0           tcn_d_causal_conv_8_tanh_s0[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "lambda_175 (Lambda)             (None, 250, 256)     0           activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tcn_spatial_dropout1d_8_s0_0.40 (None, 250, 256)     0           lambda_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_164 (Conv1D)             (None, 250, 256)     65792       tcn_spatial_dropout1d_8_s0_0.4000\n",
            "__________________________________________________________________________________________________\n",
            "add_184 (Add)                   (None, 250, 256)     0           add_183[0][0]                    \n",
            "                                                                 conv1d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tcn_d_causal_conv_16_tanh_s0 (C (None, 250, 256)     196864      add_184[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 250, 256)     0           tcn_d_causal_conv_16_tanh_s0[0][0\n",
            "__________________________________________________________________________________________________\n",
            "lambda_176 (Lambda)             (None, 250, 256)     0           activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tcn_spatial_dropout1d_16_s0_0.4 (None, 250, 256)     0           lambda_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_165 (Conv1D)             (None, 250, 256)     65792       tcn_spatial_dropout1d_16_s0_0.400\n",
            "__________________________________________________________________________________________________\n",
            "add_185 (Add)                   (None, 250, 256)     0           add_184[0][0]                    \n",
            "                                                                 conv1d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tcn_d_causal_conv_32_tanh_s0 (C (None, 250, 256)     196864      add_185[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 250, 256)     0           tcn_d_causal_conv_32_tanh_s0[0][0\n",
            "__________________________________________________________________________________________________\n",
            "lambda_177 (Lambda)             (None, 250, 256)     0           activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tcn_spatial_dropout1d_32_s0_0.4 (None, 250, 256)     0           lambda_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_166 (Conv1D)             (None, 250, 256)     65792       tcn_spatial_dropout1d_32_s0_0.400\n",
            "__________________________________________________________________________________________________\n",
            "add_186 (Add)                   (None, 250, 256)     0           add_185[0][0]                    \n",
            "                                                                 conv1d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tcn_d_causal_conv_64_tanh_s0 (C (None, 250, 256)     196864      add_186[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 250, 256)     0           tcn_d_causal_conv_64_tanh_s0[0][0\n",
            "__________________________________________________________________________________________________\n",
            "lambda_178 (Lambda)             (None, 250, 256)     0           activation_187[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tcn_spatial_dropout1d_64_s0_0.4 (None, 250, 256)     0           lambda_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_167 (Conv1D)             (None, 250, 256)     65792       tcn_spatial_dropout1d_64_s0_0.400\n",
            "__________________________________________________________________________________________________\n",
            "add_187 (Add)                   (None, 250, 256)     0           add_186[0][0]                    \n",
            "                                                                 conv1d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "tcn_d_causal_conv_128_tanh_s0 ( (None, 250, 256)     196864      add_187[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 250, 256)     0           tcn_d_causal_conv_128_tanh_s0[0][\n",
            "__________________________________________________________________________________________________\n",
            "lambda_179 (Lambda)             (None, 250, 256)     0           activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tcn_spatial_dropout1d_128_s0_0. (None, 250, 256)     0           lambda_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_168 (Conv1D)             (None, 250, 256)     65792       tcn_spatial_dropout1d_128_s0_0.40\n",
            "__________________________________________________________________________________________________\n",
            "add_189 (Add)                   (None, 250, 256)     0           conv1d_161[0][0]                 \n",
            "                                                                 conv1d_162[0][0]                 \n",
            "                                                                 conv1d_163[0][0]                 \n",
            "                                                                 conv1d_164[0][0]                 \n",
            "                                                                 conv1d_165[0][0]                 \n",
            "                                                                 conv1d_166[0][0]                 \n",
            "                                                                 conv1d_167[0][0]                 \n",
            "                                                                 conv1d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 250, 256)     0           add_189[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_11 (TimeDistri (None, 250, 10000)   2570000     activation_189[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 7,864,144\n",
            "Trainable params: 7,864,144\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k5lh2ZJRsChy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from itertools import zip_longest\n",
        "def grouper(iterable, n, fillvalue=None):\n",
        "    \"Collect data into fixed-length chunks or blocks\"\n",
        "    args = [iter(iterable)] * n\n",
        "    return zip_longest(fillvalue=fillvalue, *args)\n",
        "\n",
        "class ReutersGenerator():\n",
        "    def __init__(self, max_seq_length=250, num_words=5000):\n",
        "        self.tok = Tokenizer(num_words=num_words)\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.num_words = num_words\n",
        "    \n",
        "    def _gen_sents(self, fids):\n",
        "        return (' '.join(sent) for fid in fids for sent in reuters.sents(fid))\n",
        "    \n",
        "    def fit(self, fid_startswith='train'):\n",
        "        fids = (fid for fid in reuters.fileids() if fid.startswith(fid_startswith))\n",
        "        self.tok.fit_on_texts(self._gen_sents(fids))\n",
        "        return self\n",
        "\n",
        "    def count(self, fid_startswith='train'):\n",
        "        fids = (fid for fid in reuters.fileids() if fid.startswith(fid_startswith))\n",
        "        return sum(1 for _ in self._gen_sents(fids))\n",
        "    \n",
        "    def inverse_transform(self, X):\n",
        "        return self.tok.sequences_to_texts(X)\n",
        "    \n",
        "    def generate_pairs(self, fid_startswith='train', bs=32, \n",
        "                         max_seq_len=250, forever=True, shuffle=True):\n",
        "        fids_in = np.array([fid for fid in reuters.fileids() if fid.startswith(fid_startswith)])\n",
        "        index = np.arange(fids_in.shape[0])\n",
        "        while True:\n",
        "            np.random.shuffle(index)\n",
        "            fids = fids_in[index]\n",
        "            sents = self._gen_sents(fids)\n",
        "            for batch in grouper(sents, bs):\n",
        "                seqs = self.tok.texts_to_sequences_generator(text for text in batch if text)\n",
        "                X = pad_sequences(list(seqs), self.max_seq_length)\n",
        "                yield X, to_categorical(X, self.num_words)\n",
        "            if not forever:\n",
        "                break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SSZgXz1tHKqk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reuters_gen = ReutersGenerator(\n",
        "    num_words=MAX_NUM_WORDS, max_seq_length=MAX_SEQUENCE_LEN).fit()\n",
        "n_train = reuters_gen.count('train')\n",
        "#n_test = reuters_gen.count('test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1MR8JitksCiH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "basename = 'seq2seq-TCN-model-small'\n",
        "outfname = os.path.join(\n",
        "    OUTPUTDIR,\n",
        "    basename + '-ep{epoch:02d}.hdf5')\n",
        "cp = ModelCheckpoint(\n",
        "    outfname,\n",
        "    save_best_only=False,\n",
        "    save_weights_only=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L7AgCeZ3E_8D",
        "colab_type": "code",
        "outputId": "8ed8a2d3-ac49-4747-e0f7-614c4f45b7a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "TRAIN_MODEL = True\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 20\n",
        "\n",
        "if TRAIN_MODEL:\n",
        "  history = model.fit_generator(reuters_gen.generate_pairs('train', bs=BATCH_SIZE),\n",
        "      #validation_data=reuters_gen.generate_pairs('test', bs=BATCH_SIZE),\n",
        "      steps_per_epoch=n_train//BATCH_SIZE,\n",
        "      #validation_steps=n_test//BATCH_SIZE,\n",
        "      epochs=EPOCHS, shuffle=True, callbacks=[cp])\n",
        "else:\n",
        "  list_of_files = glob.glob(os.path.join(OUTPUTDIR, basename + '*.hdf5'))\n",
        "  list_of_files = sorted(list_of_files, key=os.path.getctime)\n",
        "  assert(len(list_of_files) > 0)\n",
        "  model = load_model(list_of_files[-1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            " 314/2517 [==>...........................] - ETA: 14:14 - loss: 0.8619 - acc: 0.8957"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VsIoTBfwnnqT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_train_hat = next(reuters_gen.generate_pairs('train'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_V9D4-TTsCiM",
        "colab_type": "code",
        "outputId": "ae4e0cd4-2794-4fb7-ec8a-de3172b6c5c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "cell_type": "code",
      "source": [
        "reuters_gen.inverse_transform(np.argmax(model.predict(X_train[:20], verbose=1), axis=2))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r20/20 [==============================] - 4s 212ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lt lt the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the of of of of of of of of of of the the the the the the the the',\n",
              " 'the the the the in in to to in in in in in in in in in in in in in in in in in year year',\n",
              " 'the 1986 february february in in dlrs dlrs dlrs dlrs in in in in in in in in in in in in in in in in the the the the said said',\n",
              " 'the said the the the the the of of of of of of of of of of of of of of of of of dlrs dlrs dlrs',\n",
              " 'the said the the the the of of of of of of of of of of of of of of of of of of of of of of of of of of',\n",
              " 'the said said said the the the the the the the the the the the the the the the the of of of dlrs',\n",
              " 'the the the the the the the the the said said',\n",
              " 'said said said said the the the the the the the the the the the the the the the the',\n",
              " 'the the the the the the the the the the the the the the the the the said said',\n",
              " 'said said the the the the the the the the the the the the the the the the the the the the the the of of of year',\n",
              " 'the the the the the the the the the the of of of of of mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln mln dlrs dlrs dlrs dlrs',\n",
              " 'the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the said said said',\n",
              " 'the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the said said said said',\n",
              " 'the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the said said',\n",
              " 'said said said said said said the the the the the the the the the the the the the the the the the the the the of of of of',\n",
              " 'the the the the the the the said',\n",
              " 'said said said the the the the the the the the the the the the the the the the the the the of of of dlrs',\n",
              " 'the said said the the the the the the the of the the of of of of of of of pct',\n",
              " 'said said the the the the the the the the said',\n",
              " 'the said the the the the the of of of the of of of of of of of dlrs dlrs']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "koH_AU6hsCiT",
        "colab_type": "code",
        "outputId": "76444f30-ea92-4740-a40e-11a12c52154e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "cell_type": "code",
      "source": [
        "reuters_gen.inverse_transform(X_train[:20])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lt to charge corp said it to charges of to the social security administration and agreed to pay 1 2 mln dlrs in and costs to the u s government',\n",
              " 'the company also reached agreements in principle for an 8 1 mln dlr settlement of class action law',\n",
              " \"about 2 9 mln dlrs of the class action settlement will be provided by ' s insurance carrier\",\n",
              " 'the settlement is contingent on court approval after notice to class members it said',\n",
              " 'the case settlement all charges including and statement except for to which',\n",
              " \"the settlement includes the lifting of the government ' s suspension the of the federal civil claims suit and all charges against the individuals\",\n",
              " 'of the 2 9 mln dlrs the insurance carrier will provide for the civil settlement 750 000 dlrs will go to settle a lawsuit',\n",
              " 'for the year ended december 31 reported a net loss of 38 5 mln dlrs',\n",
              " 'the year end results include an 8 0 mln dlrs provision for future legal and or settlement costs to cover the civil and announced today',\n",
              " 'also said it named as president and chief executive officer robert who resigned as chairman and chief executive officer as part of the settlement of the',\n",
              " 'formerly served as executive vice president and chief operating officer',\n",
              " 'the company also said that due to the sluggish it does not expect to be profitable in the first quarter but is optimistic about the outlook for the year',\n",
              " 'for the first quarter of 1986 the company reported net income of 875 000 dlrs on sales of 66 0 mln dlrs',\n",
              " 'was among five executives who were charged along with three former officers in a 1985 federal from a 115 mln contract awarded to in 1981 to build a computer network for the social security administration',\n",
              " 'the were accused of to government officials and the social security administration',\n",
              " 'and other were also charged with providing testimony and justice during a securities and exchange commission investigation',\n",
              " 'under the settlement announced today federal agreed to all charges against and three other under a one year agreement',\n",
              " 'the charges would then be dropped if the successfully complete the period',\n",
              " 'details of the requirements in the agreement were not immediately available',\n",
              " 'and lt to make acquisition and inc said it has agreed to acquire electric parts distributor b and w electric supply co for an undisclosed amount of cash']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "WcYZnmYiG1Tw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pXd7v4MBG1WW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def iter_labels(selection='train'):\n",
        "    for fid in reuters.fileids():\n",
        "        if fid.startswith(selection):\n",
        "            for sent in reuters.sents(fid):\n",
        "                yield reuters.categories(fid)\n",
        "labels_train = np.array(list(iter_labels('train')))\n",
        "labels_test = np.array(list(iter_labels('test')))\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer().fit(labels_train)\n",
        "y_train = mlb.transform(labels_train)\n",
        "y_test = mlb.transform(labels_test)\n",
        "\n",
        "def iter_sents(selection='train'):\n",
        "    for fid in reuters.fileids():\n",
        "        if fid.startswith(selection):\n",
        "            for sent in reuters.sents(fid):\n",
        "                yield \" \".join(sent)\n",
        "data_train = np.array(list(iter_sents('train')))\n",
        "data_test = np.array(list(iter_sents('test')))\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer.fit_on_texts(data_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(data_train)\n",
        "X_test = tokenizer.texts_to_sequences(data_test)\n",
        "\n",
        "X_train = pad_sequences(X_train, MAX_SEQUENCE_LEN)\n",
        "X_test = pad_sequences(X_test, MAX_SEQUENCE_LEN)\n",
        "\n",
        "def data_generator(X_in, batch_size=32, shuffle=True, repeat=True):\n",
        "    index = np.arange(X_in.shape[0])\n",
        "    while True:\n",
        "        np.random.shuffle(index)\n",
        "        X = X_in[index]\n",
        "        n = X.shape[0]//batch_size\n",
        "        for chunk in np.split(X[:n*batch_size], n):\n",
        "            yield chunk, to_categorical(chunk, MAX_NUM_WORDS)\n",
        "        rest = X[n*batch_size:]\n",
        "        if rest.shape[0]:\n",
        "            yield rest, to_categorical(rest, MAX_NUM_WORDS)\n",
        "        if not repeat:\n",
        "            break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_UemOL34sCiY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_enc = Model(input_layer, encoder)\n",
        "vecs = model_enc.predict(X_hat[:1000], verbose=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wekWSy1nsCic",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "vecs_reduced = TSNE().fit_transform(vecs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M74X2ZjasCig",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "categories = [(cat, len(reuters.fileids(categories=cat))) for cat in reuters.categories()]\n",
        "topn = [cat for cat, _ in sorted(categories, key=lambda x: -x[1])[:10]]\n",
        "\n",
        "indexes = []\n",
        "for cat in topn:\n",
        "    index = []\n",
        "    for pos, cats in enumerate(labels_train[:1000]):\n",
        "        if cat in cats:\n",
        "            index.append(pos)\n",
        "    indexes.append((cat, index))\n",
        "\n",
        "for cat, index in indexes:\n",
        "    plt.scatter(vecs_reduced[index,0], vecs_reduced[index,1], label=cat)\n",
        "plt.legend(bbox_to_anchor=(1, 1.01))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0AsvOddQsCio",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}