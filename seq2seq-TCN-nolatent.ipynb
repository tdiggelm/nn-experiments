{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq-TCN.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "W1_uV8WoFXQu",
        "colab_type": "code",
        "outputId": "9d1d77c8-2d94-412b-d157-954ffaf4d792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!mkdir -p /content/drive/My\\ Drive/nn_output"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xscbWz8wGH0J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "OUTPUTDIR='/content/drive/My Drive/nn_output'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jrCPRQxBFJqP",
        "colab_type": "code",
        "outputId": "99e7f097-9c46-48f1-930c-9de25df85901",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install keras-TCN\n",
        "\n",
        "from keras.layers import (Bidirectional, Dense, Embedding, Input, Lambda, InputLayer, Reshape\n",
        "                          , LSTM, RepeatVector, TimeDistributed)\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from tcn import TCN\n",
        "from keras.utils import to_categorical\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.initializers import Constant\n",
        "import numpy as np\n",
        "from nltk.corpus import reuters\n",
        "from itertools import chain\n",
        "import nltk\n",
        "nltk.download('reuters')\n",
        "nltk.download('punkt')\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import os.path\n",
        "import glob"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-TCN in /usr/local/lib/python3.6/dist-packages (2.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-TCN) (1.14.6)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-TCN) (2.2.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-TCN) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-TCN) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-TCN) (1.11.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-TCN) (1.0.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-TCN) (1.0.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-TCN) (2.8.0)\n",
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k5lh2ZJRsChy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from itertools import zip_longest\n",
        "def grouper(iterable, n, fillvalue=None):\n",
        "    \"Collect data into fixed-length chunks or blocks\"\n",
        "    args = [iter(iterable)] * n\n",
        "    return zip_longest(fillvalue=fillvalue, *args)\n",
        "\n",
        "class ReutersGenerator():\n",
        "    def __init__(self, max_seq_length=250, num_words=5000):\n",
        "        self.tok = Tokenizer(num_words=num_words)\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.num_words = num_words\n",
        "    \n",
        "    def _gen_sents(self, fids):\n",
        "        return (' '.join(sent) for fid in fids for sent in reuters.sents(fid))\n",
        "    \n",
        "    def fit(self, fid_startswith='train'):\n",
        "        fids = (fid for fid in reuters.fileids() if fid.startswith(fid_startswith))\n",
        "        self.tok.fit_on_texts(self._gen_sents(fids))\n",
        "        return self\n",
        "\n",
        "    def count(self, fid_startswith='train'):\n",
        "        fids = (fid for fid in reuters.fileids() if fid.startswith(fid_startswith))\n",
        "        return sum(1 for _ in self._gen_sents(fids))\n",
        "    \n",
        "    def inverse_transform(self, X):\n",
        "        return self.tok.sequences_to_texts(X)\n",
        "    \n",
        "    def generate_pairs(self, fid_startswith='train', bs=32, \n",
        "                         max_seq_len=250, forever=True, shuffle=True):\n",
        "        fids_in = np.array([fid for fid in reuters.fileids() if fid.startswith(fid_startswith)])\n",
        "        index = np.arange(fids_in.shape[0])\n",
        "        while True:\n",
        "            np.random.shuffle(index)\n",
        "            fids = fids_in[index]\n",
        "            sents = self._gen_sents(fids)\n",
        "            for batch in grouper(sents, bs):\n",
        "                seqs = self.tok.texts_to_sequences_generator(text for text in batch if text)\n",
        "                X = pad_sequences(list(seqs), self.max_seq_length)\n",
        "                yield X, to_categorical(X, self.num_words)\n",
        "            if not forever:\n",
        "                break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SSZgXz1tHKqk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "reuters_gen = ReutersGenerator(\n",
        "    num_words=MAX_NUM_WORDS, max_seq_length=MAX_SEQUENCE_LEN).fit()\n",
        "n_train = reuters_gen.count('train')\n",
        "#n_test = reuters_gen.count('test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S6v0kPz67sPl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "fece2b5f-2d05-4ad5-c2a0-86f3a31fd454"
      },
      "cell_type": "code",
      "source": [
        "if not os.path.isfile(\"glove.6B.100d.txt\"):\n",
        "  !wget \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "  !unzip \"glove.6B.zip\"\n",
        "\n",
        "# get glove coeff matrix\n",
        "embeddings_index = {}\n",
        "with open(\"glove.6B.100d.txt\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "print('Found %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "# prepare pre-learned embedding matrix\n",
        "embdedding_dim = 100\n",
        "word_index = reuters_gen.tok.word_index\n",
        "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
        "embedding_matrix = np.zeros((num_words, embdedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i > MAX_NUM_WORDS:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-15 10:00:38--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-01-15 10:00:38--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  46.6MB/s    in 2m 13s  \n",
            "\n",
            "2019-01-15 10:02:52 (6.16 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TXHnYTNY7zsD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2193
        },
        "outputId": "627c4ff7-913b-4c5f-98ea-da31fed9530f"
      },
      "cell_type": "code",
      "source": [
        "USE_GLOVE = True\n",
        "MAX_SEQUENCE_LEN = 250\n",
        "MAX_NUM_WORDS = 10000\n",
        "\n",
        "kernel_size = 3\n",
        "n_dilations = 8\n",
        "n_hidden = 128\n",
        "embedding_size = 100\n",
        "dropout=0.4\n",
        "\n",
        "input_layer = Input(shape=(MAX_SEQUENCE_LEN,))\n",
        "encoder = None\n",
        "if not USE_GLOVE:\n",
        "  encoder = Embedding(MAX_NUM_WORDS, embedding_size)(input_layer)\n",
        "else:\n",
        "  encoder = Embedding(num_words, embdedding_dim, \n",
        "                      input_length=MAX_SEQUENCE_LEN, \n",
        "                      embeddings_initializer=Constant(embedding_matrix),\n",
        "                      trainable=True)(input_layer)\n",
        "encoder = TCN(return_sequences=True,\n",
        "              kernel_size=kernel_size,\n",
        "              dilations=[2**n for n in range(n_dilations)],\n",
        "              nb_filters=n_hidden,\n",
        "              nb_stacks=1,\n",
        "              dropout_rate=dropout)(encoder)\n",
        "output_layer = TimeDistributed(Dense(MAX_NUM_WORDS, activation='softmax'))(encoder)\n",
        "model = Model(input_layer, output_layer)\n",
        "optimizer = optimizers.Adam(lr=0.002, clipnorm=0.4)\n",
        "model.compile(optimizer=optimizer, metrics=['accuracy'], loss='categorical_crossentropy')\n",
        "print(model.summary())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 250)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 250, 100)     1000100     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tcn_initial_conv (Conv1D)       (None, 250, 128)     12928       embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tcn_d_causal_conv_1_tanh_s0 (Co (None, 250, 128)     49280       tcn_initial_conv[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 250, 128)     0           tcn_d_causal_conv_1_tanh_s0[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "lambda_9 (Lambda)               (None, 250, 128)     0           activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tcn_spatial_dropout1d_1_s0_0.40 (None, 250, 128)     0           lambda_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_9 (Conv1D)               (None, 250, 128)     16512       tcn_spatial_dropout1d_1_s0_0.4000\n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 250, 128)     0           tcn_initial_conv[0][0]           \n",
            "                                                                 conv1d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tcn_d_causal_conv_2_tanh_s0 (Co (None, 250, 128)     49280       add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 250, 128)     0           tcn_d_causal_conv_2_tanh_s0[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "lambda_10 (Lambda)              (None, 250, 128)     0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tcn_spatial_dropout1d_2_s0_0.40 (None, 250, 128)     0           lambda_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_10 (Conv1D)              (None, 250, 128)     16512       tcn_spatial_dropout1d_2_s0_0.4000\n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 250, 128)     0           add_10[0][0]                     \n",
            "                                                                 conv1d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tcn_d_causal_conv_4_tanh_s0 (Co (None, 250, 128)     49280       add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 250, 128)     0           tcn_d_causal_conv_4_tanh_s0[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "lambda_11 (Lambda)              (None, 250, 128)     0           activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tcn_spatial_dropout1d_4_s0_0.40 (None, 250, 128)     0           lambda_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_11 (Conv1D)              (None, 250, 128)     16512       tcn_spatial_dropout1d_4_s0_0.4000\n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 250, 128)     0           add_11[0][0]                     \n",
            "                                                                 conv1d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tcn_d_causal_conv_8_tanh_s0 (Co (None, 250, 128)     49280       add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 250, 128)     0           tcn_d_causal_conv_8_tanh_s0[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "lambda_12 (Lambda)              (None, 250, 128)     0           activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tcn_spatial_dropout1d_8_s0_0.40 (None, 250, 128)     0           lambda_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_12 (Conv1D)              (None, 250, 128)     16512       tcn_spatial_dropout1d_8_s0_0.4000\n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 250, 128)     0           add_12[0][0]                     \n",
            "                                                                 conv1d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tcn_d_causal_conv_16_tanh_s0 (C (None, 250, 128)     49280       add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 250, 128)     0           tcn_d_causal_conv_16_tanh_s0[0][0\n",
            "__________________________________________________________________________________________________\n",
            "lambda_13 (Lambda)              (None, 250, 128)     0           activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tcn_spatial_dropout1d_16_s0_0.4 (None, 250, 128)     0           lambda_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_13 (Conv1D)              (None, 250, 128)     16512       tcn_spatial_dropout1d_16_s0_0.400\n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 250, 128)     0           add_13[0][0]                     \n",
            "                                                                 conv1d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tcn_d_causal_conv_32_tanh_s0 (C (None, 250, 128)     49280       add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 250, 128)     0           tcn_d_causal_conv_32_tanh_s0[0][0\n",
            "__________________________________________________________________________________________________\n",
            "lambda_14 (Lambda)              (None, 250, 128)     0           activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tcn_spatial_dropout1d_32_s0_0.4 (None, 250, 128)     0           lambda_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_14 (Conv1D)              (None, 250, 128)     16512       tcn_spatial_dropout1d_32_s0_0.400\n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 250, 128)     0           add_14[0][0]                     \n",
            "                                                                 conv1d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tcn_d_causal_conv_64_tanh_s0 (C (None, 250, 128)     49280       add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 250, 128)     0           tcn_d_causal_conv_64_tanh_s0[0][0\n",
            "__________________________________________________________________________________________________\n",
            "lambda_15 (Lambda)              (None, 250, 128)     0           activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tcn_spatial_dropout1d_64_s0_0.4 (None, 250, 128)     0           lambda_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_15 (Conv1D)              (None, 250, 128)     16512       tcn_spatial_dropout1d_64_s0_0.400\n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 250, 128)     0           add_15[0][0]                     \n",
            "                                                                 conv1d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tcn_d_causal_conv_128_tanh_s0 ( (None, 250, 128)     49280       add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 250, 128)     0           tcn_d_causal_conv_128_tanh_s0[0][\n",
            "__________________________________________________________________________________________________\n",
            "lambda_16 (Lambda)              (None, 250, 128)     0           activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tcn_spatial_dropout1d_128_s0_0. (None, 250, 128)     0           lambda_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_16 (Conv1D)              (None, 250, 128)     16512       tcn_spatial_dropout1d_128_s0_0.40\n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 250, 128)     0           conv1d_9[0][0]                   \n",
            "                                                                 conv1d_10[0][0]                  \n",
            "                                                                 conv1d_11[0][0]                  \n",
            "                                                                 conv1d_12[0][0]                  \n",
            "                                                                 conv1d_13[0][0]                  \n",
            "                                                                 conv1d_14[0][0]                  \n",
            "                                                                 conv1d_15[0][0]                  \n",
            "                                                                 conv1d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 250, 128)     0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, 250, 10000)   1290000     activation_18[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 2,829,364\n",
            "Trainable params: 2,829,364\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1MR8JitksCiH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "basename = 'seq2seq-TCN-model-small-nolatent'\n",
        "outfname = os.path.join(\n",
        "    OUTPUTDIR,\n",
        "    basename + '-ep{epoch:02d}.hdf5')\n",
        "cp = ModelCheckpoint(\n",
        "    outfname,\n",
        "    save_best_only=False,\n",
        "    save_weights_only=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L7AgCeZ3E_8D",
        "colab_type": "code",
        "outputId": "85556536-e1bc-4646-90be-bd18a4664730",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "TRAIN_MODEL = True\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 1\n",
        "\n",
        "if TRAIN_MODEL:\n",
        "  history = model.fit_generator(reuters_gen.generate_pairs('train', bs=BATCH_SIZE),\n",
        "      #validation_data=reuters_gen.generate_pairs('test', bs=BATCH_SIZE),\n",
        "      steps_per_epoch=n_train//BATCH_SIZE,\n",
        "      #validation_steps=n_test//BATCH_SIZE,\n",
        "      epochs=EPOCHS, shuffle=True, callbacks=[cp])\n",
        "else:\n",
        "  list_of_files = glob.glob(os.path.join(OUTPUTDIR, basename + '*.hdf5'))\n",
        "  list_of_files = sorted(list_of_files, key=os.path.getctime)\n",
        "  assert(len(list_of_files) > 0)\n",
        "  model = load_model(list_of_files[-1])\n",
        "  print('Loaded model from \\'%s\\'' % list_of_files[-1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            " 373/1258 [=======>......................] - ETA: 5:19 - loss: 0.5023 - acc: 0.9436"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VsIoTBfwnnqT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_test, X_test_hat = next(reuters_gen.generate_pairs('test'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_V9D4-TTsCiM",
        "colab_type": "code",
        "outputId": "299ee669-502f-4ce6-ffea-8b901ae28856",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "cell_type": "code",
      "source": [
        "reuters_gen.inverse_transform(np.argmax(model.predict(X_train[:20], verbose=1), axis=2))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r20/20 [==============================] - 1s 60ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['national comparison bank says it cutting base lending rate to 10 5 pct from 11 pct',\n",
              " 'national comparison bank says it cutting base lending rate to 10 5 pct from 11 pct',\n",
              " 'borg warner to sell industrial products business for about 240 mln dlrs',\n",
              " 'borg warner to sell industrial products business for about 240 mln dlrs',\n",
              " 'louisiana pacific lt to sell forces louisiana pacific corp said it plans to sell its bushel in embassy and 18 000 acres of to construction co',\n",
              " 'the company said the be embassy in early april',\n",
              " 'terms were not disclosed',\n",
              " \"approached ship in oil row heads for consortium a approached research ship by warships and air force km left for the 460 to press 577 ' s case in an freight row with greece over oil rights the semi official resigned news agency said\",\n",
              " 'the ship set off this morning from the port of with sum bushel and embassy by the agency said',\n",
              " 'prime minister said last night the ship would not go into international waters unless greece did the same',\n",
              " 'we are waiting for the first move from them he told approached radio in london',\n",
              " 'renault telephone lt to sell properties treasurer telephone enterprises inc said it has accepted an offer to sell its cable television properties in michigan 318 forces and louisiana for a substantial gain',\n",
              " 'the company said details were not disclosed',\n",
              " 'u k',\n",
              " \"intervention board details ec sugar sales a total 60 500 tonnes of current series white sugar received export reaction of a maximum 44 aggressively european currency units ecus per 100 kilos at today ' s european community ec tender the u k\",\n",
              " 'intervention board said',\n",
              " 'out of this traders in france received 18 000 tonnes in denmark 15 000 in west germany 12 250 in the netherlands 12 000 and in belgium 3 250 tonnes it added',\n",
              " 'earlier today london traders had expected the expense for the current season determination campaign for spot to end hughes to be between 44 10 and 44 50 ecus per 100 kilos',\n",
              " \"traders had also forecast today ' s total renault sugar tonnage export core to be between 60 000 and 70 000 tonnes versus 71 000 last week when the forces was 43 postings ecus\",\n",
              " 'cumulative export for the current 1986 87 season now stand at 1 powers 270 tonnes 40 weeks']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "koH_AU6hsCiT",
        "colab_type": "code",
        "outputId": "710976ef-61ed-4f4d-e705-4c161cf9aab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "cell_type": "code",
      "source": [
        "reuters_gen.inverse_transform(X_test[:20])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['national westminster bank says it cutting base lending rate to 10 5 pct from 11 pct',\n",
              " 'national westminster bank says it cutting base lending rate to 10 5 pct from 11 pct',\n",
              " 'borg warner to sell industrial products business for about 240 mln dlrs',\n",
              " 'borg warner to sell industrial products business for about 240 mln dlrs',\n",
              " 'louisiana pacific lt to sell sawmill louisiana pacific corp said it plans to sell its sawmill in oregon and 18 000 acres of to construction co',\n",
              " 'the company said the be finalized in early april',\n",
              " 'terms were not disclosed',\n",
              " \"turkish ship in oil row heads for aegean a turkish research ship by warships and air force planes left for the aegean to press ankara ' s case in an escalating row with greece over oil rights the semi official anatolian news agency said\",\n",
              " 'the ship set off this morning from the port of with flags flying and watched by the agency said',\n",
              " 'prime minister said last night the ship would not go into international waters unless greece did the same',\n",
              " 'we are waiting for the first move from them he told turkish radio in london',\n",
              " 'century telephone lt to sell properties century telephone enterprises inc said it has accepted an offer to sell its cable television properties in michigan florida arkansas and louisiana for a substantial gain',\n",
              " 'the company said details were not disclosed',\n",
              " 'u k',\n",
              " \"intervention board details ec sugar sales a total 60 500 tonnes of current series white sugar received export rebates of a maximum 44 819 european currency units ecus per 100 kilos at today ' s european community ec tender the u k\",\n",
              " 'intervention board said',\n",
              " 'out of this traders in france received 18 000 tonnes in denmark 15 000 in west germany 12 250 in the netherlands 12 000 and in belgium 3 250 tonnes it added',\n",
              " 'earlier today london traders had expected the subsidy for the current season whites campaign for licences to end aug to be between 44 10 and 44 50 ecus per 100 kilos',\n",
              " \"traders had also forecast today ' s total authorised sugar tonnage export awards to be between 60 000 and 70 000 tonnes versus 71 000 last week when the restitution was 43 248 ecus\",\n",
              " 'cumulative export for the current 1986 87 season now stand at 1 915 270 tonnes 40 weeks']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "WcYZnmYiG1Tw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pXd7v4MBG1WW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def iter_labels(selection='train'):\n",
        "    for fid in reuters.fileids():\n",
        "        if fid.startswith(selection):\n",
        "            for sent in reuters.sents(fid):\n",
        "                yield reuters.categories(fid)\n",
        "labels_train = np.array(list(iter_labels('train')))\n",
        "labels_test = np.array(list(iter_labels('test')))\n",
        "\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer().fit(labels_train)\n",
        "y_train = mlb.transform(labels_train)\n",
        "y_test = mlb.transform(labels_test)\n",
        "\n",
        "def iter_sents(selection='train'):\n",
        "    for fid in reuters.fileids():\n",
        "        if fid.startswith(selection):\n",
        "            for sent in reuters.sents(fid):\n",
        "                yield \" \".join(sent)\n",
        "data_train = np.array(list(iter_sents('train')))\n",
        "data_test = np.array(list(iter_sents('test')))\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer.fit_on_texts(data_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(data_train)\n",
        "X_test = tokenizer.texts_to_sequences(data_test)\n",
        "\n",
        "X_train = pad_sequences(X_train, MAX_SEQUENCE_LEN)\n",
        "X_test = pad_sequences(X_test, MAX_SEQUENCE_LEN)\n",
        "\n",
        "def data_generator(X_in, batch_size=32, shuffle=True, repeat=True):\n",
        "    index = np.arange(X_in.shape[0])\n",
        "    while True:\n",
        "        np.random.shuffle(index)\n",
        "        X = X_in[index]\n",
        "        n = X.shape[0]//batch_size\n",
        "        for chunk in np.split(X[:n*batch_size], n):\n",
        "            yield chunk, to_categorical(chunk, MAX_NUM_WORDS)\n",
        "        rest = X[n*batch_size:]\n",
        "        if rest.shape[0]:\n",
        "            yield rest, to_categorical(rest, MAX_NUM_WORDS)\n",
        "        if not repeat:\n",
        "            break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_UemOL34sCiY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_enc = Model(input_layer, encoder)\n",
        "vecs = model_enc.predict(X_hat[:1000], verbose=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wekWSy1nsCic",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "vecs_reduced = TSNE().fit_transform(vecs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M74X2ZjasCig",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "categories = [(cat, len(reuters.fileids(categories=cat))) for cat in reuters.categories()]\n",
        "topn = [cat for cat, _ in sorted(categories, key=lambda x: -x[1])[:10]]\n",
        "\n",
        "indexes = []\n",
        "for cat in topn:\n",
        "    index = []\n",
        "    for pos, cats in enumerate(labels_train[:1000]):\n",
        "        if cat in cats:\n",
        "            index.append(pos)\n",
        "    indexes.append((cat, index))\n",
        "\n",
        "for cat, index in indexes:\n",
        "    plt.scatter(vecs_reduced[index,0], vecs_reduced[index,1], label=cat)\n",
        "plt.legend(bbox_to_anchor=(1, 1.01))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0AsvOddQsCio",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}