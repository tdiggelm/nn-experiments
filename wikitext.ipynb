{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wikitext.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tdiggelm/nn-experiments/blob/master/wikitext.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "RqlZ6v8PU4Fh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "1c39161f-d26f-4df8-e084-8327a603a443"
      },
      "cell_type": "code",
      "source": [
        "!pip install keras-TCN\n",
        "import os\n",
        "import numpy as np\n",
        "from keras import layers, initializers, models, optimizers\n",
        "\n",
        "from tcn import TCN\n",
        "\n",
        "if not os.path.isfile('wikitext-103-v1.zip'):\n",
        "  !wget https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-103-v1.zip\n",
        "  !unzip wikitext-103-v1.zip"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-TCN in /usr/local/lib/python3.6/dist-packages (2.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-TCN) (1.14.6)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-TCN) (2.2.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-TCN) (2.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-TCN) (1.11.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-TCN) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-TCN) (1.0.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-TCN) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-TCN) (1.0.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "swcPatsrG9D0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "MAX_SEQ_LENGTH = 10\n",
        "MAX_NUM_WORDS = 10000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yJQn77zAVZi3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tok2id = {'<unk>': 0}\n",
        "id2tok = {0: '<unk>'}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WQGcRVShYg-6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from itertools import islice\n",
        "\n",
        "def fit_dict(tokens):\n",
        "  for tok in tokens:\n",
        "    n = len(tok2id)\n",
        "    if not tok in tok2id:\n",
        "      tok2id[tok] = n\n",
        "      id2tok[n] = tok\n",
        "\n",
        "def wikitext_tokens(fname):\n",
        "  with open(fname) as f:\n",
        "    for line in f:\n",
        "      line = line.strip()\n",
        "      if line and not line.startswith('='):\n",
        "        line = line.lower()\n",
        "        tokens = line.split(' ')\n",
        "        for token in tokens:\n",
        "          yield token\n",
        "\n",
        "def transform_token(tok):\n",
        "  return tok2id[tok] if tok in tok2id else tok2id['<unk>']\n",
        "\n",
        "def transform_token_seq(toks):\n",
        "  return [transform_token(tok) for tok in toks]\n",
        "\n",
        "def one_hot(tok):\n",
        "  return to_categorical(tok, len(tok2id))\n",
        "          \n",
        "def gen_pairs(tokens, min_ngram=2, max_ngram=10):\n",
        "  tokgen = iter(tokens)\n",
        "  prev_toks = []\n",
        "  for _ in range(min_ngram):\n",
        "      prev_toks.append(next(tokgen))\n",
        "  while True:\n",
        "    curr_tok = next(tokgen)\n",
        "    ngramlen = min(np.random.randint(min_ngram, max_ngram), len(prev_toks))\n",
        "    yield prev_toks[-ngramlen:] ,curr_tok\n",
        "    if len(prev_toks) > max_ngram-1:\n",
        "      prev_toks.pop(0)\n",
        "    prev_toks.append(curr_tok)\n",
        "    \n",
        "def gen_batches(dataset='train', bs=32):\n",
        "  tokens = wikitext_tokens('wikitext-103/wiki.%s.tokens' % dataset)\n",
        "  tokens = (transform_token(tok) for tok in tokens)\n",
        "  pairgen = gen_pairs(tokens)\n",
        "  while True:\n",
        "    Xs = []\n",
        "    ys = []\n",
        "    for x, y in islice(pairgen, bs):\n",
        "      Xs.append(x)\n",
        "      ys.append(y)\n",
        "    yield (pad_sequences(Xs, MAX_SEQ_LENGTH),\n",
        "      to_categorical(np.array(ys), MAX_NUM_WORDS))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rqb_SbN5czcU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fit_dict(wikitext_tokens('wikitext-103/wiki.train.tokens'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IpRY_T1uYSIj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "145554e9-05a7-4292-d3cf-7db9e1fa87f0"
      },
      "cell_type": "code",
      "source": [
        "if not os.path.isfile(\"glove.6B.100d.txt\"):\n",
        "  !wget \"http://nlp.stanford.edu/data/glove.6B.zip\"\n",
        "  !unzip \"glove.6B.zip\"\n",
        "\n",
        "# get glove coeff matrix\n",
        "embeddings_index = {}\n",
        "with open(\"glove.6B.100d.txt\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "print('Found %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "# prepare pre-learned embedding matrix\n",
        "embdedding_dim = 100\n",
        "word_index = tok2id\n",
        "num_words = len(word_index)+1 if not MAX_NUM_WORDS else min(MAX_NUM_WORDS, len(word_index)) + 1\n",
        "embedding_matrix = np.zeros((num_words, embdedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if MAX_NUM_WORDS and i > MAX_NUM_WORDS:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-18 14:28:43--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-01-18 14:28:43--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  10.3MB/s    in 40s     \n",
            "\n",
            "2019-01-18 14:29:23 (20.8 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UqxKS5zDGjZN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "62f7aadf-8a86-4a86-fe7e-10ebc1985e3b"
      },
      "cell_type": "code",
      "source": [
        "embedding = layers.Embedding(num_words, embdedding_dim, \n",
        "            input_length=MAX_SEQ_LENGTH, \n",
        "            embeddings_initializer=initializers.Constant(embedding_matrix),\n",
        "            trainable=True)\n",
        "model = models.Sequential()\n",
        "model.add(embedding)\n",
        "model.add(layers.Bidirectional(layers.LSTM(100, return_sequences=False)))\n",
        "#model.add(layers.Bidirectional(layers.GRU(300, return_sequences=True)))\n",
        "#model.add(layers.Bidirectional(layers.GRU(300, return_sequences=True)))\n",
        "#model.add(layers.Lambda(lambda x: x[:, -1, :]))\n",
        "model.add(layers.Dense(MAX_NUM_WORDS, activation='softmax'))\n",
        "optimizer = optimizers.SGD(lr=0.001, clipnorm=0.1)\n",
        "model.compile(optimizer=optimizer,\n",
        "              metrics=['accuracy'],\n",
        "              loss='categorical_crossentropy')\n",
        "model.summary()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, 10, 100)           200       \n",
            "_________________________________________________________________\n",
            "bidirectional_10 (Bidirectio (None, 200)               160800    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10000)             2010000   \n",
            "=================================================================\n",
            "Total params: 2,171,000\n",
            "Trainable params: 2,171,000\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JyiDGEqrG4IF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "10289e2d-4474-4856-ea64-d9649adc7dcb"
      },
      "cell_type": "code",
      "source": [
        "model.fit_generator(gen_batches('train'),\n",
        "                   steps_per_epoch=100, epochs=3)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "100/100 [==============================] - 45s 446ms/step - loss: 9.2100 - acc: 0.0666\n",
            "Epoch 2/3\n",
            "100/100 [==============================] - 42s 421ms/step - loss: 9.2094 - acc: 0.0759\n",
            "Epoch 3/3\n",
            "100/100 [==============================] - 41s 415ms/step - loss: 9.2088 - acc: 0.0653\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f97f6a2feb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "P-FGbKVfb1Aq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "4d857d78-60eb-4a8e-eb27-566555ef3d09"
      },
      "cell_type": "code",
      "source": [
        "X_test, y_test = next(gen_batches('test'))\n",
        "X_test"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[     0,      0,      0, ...,      0,   1141, 115695],\n",
              "       [     0,      0,      0, ...,   1141, 115695,     24],\n",
              "       [     0,      0,      0, ..., 115695,     24,    144],\n",
              "       ...,\n",
              "       [     0,      0,      0, ...,    472,    129,   3697],\n",
              "       [     0,      0,      0, ...,    129,   3697,     33],\n",
              "       [     0,      0,      0, ...,   3697,     33,     25]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "YZ-gq8FBb2Ge",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "29891dd6-4d1d-4a42-8c5e-9f57bdf70d5a"
      },
      "cell_type": "code",
      "source": [
        "model.predict_classes(X_test)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
              "       14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "0ZGtj-Dvei-5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}